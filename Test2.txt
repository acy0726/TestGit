Deep Learning Recommendation Model for Personalization and Recommendation Systems


심층 학습의 출현으로 신경망 기반 권장 모델이 개인화 및 권장 작업을 처리하는 중요한 도구로 부상했습니다. 이러한 네트워크는 범주 형 기능을 처리해야하기 때문에 다른 심층 학습 네트워크와 크게 다르며 잘 연구되거나 이해되지 않습니다. 이 백서에서는 최첨단 DLRM (Deep Learning Recommendation Model)을 개발하고 PyTorch 및 Caffe2 프레임 워크에서 구현을 제공합니다. 또한 데이터 병렬 처리를 활용하여 메모리 제약 조건을 줄이기 위해 포함 테이블에서 모델 병렬 처리를 사용하는 특수화 된 병렬화 기법을 설계하여 완전 연결된 계층에서 계산을 확장합니다. DLRM을 기존 권장 모델과 비교하고 Big Basin AI 플랫폼에서 성능을 특성화하여 향후 알고리즘 실험 및 시스템 공동 설계의 벤치 마크로서의 유용성을 입증합니다.


개인화 및 추천 시스템은 현재 광고 클릭률 (CTR) 예측 및 순위를 포함하여 대형 인터넷 회사에서 다양한 작업을 위해 배포됩니다. 이러한 방법은 오랜 역사가 있지만 이러한 접근 방식은 최근에야 신경 네트워크를 채택했습니다.
두 가지 주요 관점은 개인화 및 권장을위한 심층 학습 모델의 아키텍처 설계에 기여했습니다. 첫 번째는 추천 시스템의 관점에서 비롯됩니다. 이러한 시스템은 처음에는 콘텐츠 필터링을 사용하여 전문가 집단이 제품을 범주로 분류하고 사용자는 선호하는 범주를 선택하고 선호도에 따라 일치 시켰습니다 [22]. 필드는 이후 협업 필터링을 사용하도록 발전했으며, 권장 사항은 제품에 제공된 이전 등급과 같은 과거 사용자 행동을 기반으로합니다. 사용자와 제품을 그룹화하여 권고 사항을 제공하는 Neighborhood 방법 [21]과 매트릭스 인수 분해 기술 [9, 17]을 통해 암묵적인 요인에 의해 사용자와 제품을 특성화하는 잠재 요인 방법이 나중에 성공적으로 배포되었습니다. 두 번째 관점은 주어진 데이터를 기반으로 사건의 확률을 분류하거나 예측하기 위해 통계적 모델에 의존하는 예측 분석에서 나온다. 예측 모델은 선형 및 로지스틱 회귀와 같은 간단한 모델을 사용하는 것에서 깊은 네트워크를 통합 한 모델로 전환되었습니다. 범주 형 데이터를 처리하기 위해 이러한 모델은 추상 공간에서 단일 및 다중 핫 벡터를 고밀도 표현으로 변환하는 삽입 사용을 채택했습니다 [20]. 이 추상 공간은 추천 시스템에 의해 발견 된 잠재 요인의 공간으로 해석 될 수 있습니다. 본고에서는 위에서 설명한 두 가지 관점의 결합으로 고안된 개인화 모델을 소개합니다. 이 모델은 밀도 데이터를 표현하는 희소 피처를 처리하기 위해 임베딩을 사용하고 밀집 피처를 처리하기 위해 MLP (Multipurface Perceptron)를 사용하고 [24]에서 제안 된 통계 기법을 사용하여 이러한 피쳐를 명시 적으로 상호 작용합니다. 마지막으로 다른 MLP와의 상호 작용을 사후 처리하여 이벤트 확률을 찾습니다. 이 모델을 DLRM (Deep Learning Recommendation Model)이라고 부릅니다. 그림 1을 참조하십시오.이 모델의 PyTorch 및 Caffe2 구현은이 원고의 발행과 함께 테스트 및 실험을 위해 발표 될 예정입니다.

개인화 및 추천 시스템은 현재 대형 인터넷 업체에서 광고 클릭율(CTR) 예측 및 순위 등 다양한 업무를 위해 구축되어 있다. 비록 이러한 방법들이 긴 역사를 가지고 있지만, 이러한 접근방식은 최근에야 신경망을 수용했다.
개인화 및 권고를 위한 심층 학습 모델의 아키텍처 설계에 두 가지 주요 관점이 기여했다. 첫 번째는 추천 시스템의 관점에서 나온다. 이러한 시스템은 처음에 일련의 전문가들이 제품을 카테고리로 분류하는 콘텐츠 필터링을 채택했고, 사용자들은 선호하는 카테고리를 선택하고 선호도에 따라 일치시켰다[22]. 이 필드는 이후 협업 필터링을 사용하도록 진화했으며, 여기서 권고사항은 제품에 부여된 이전 등급과 같은 과거의 사용자 행동에 기초한다. 사용자와 제품을 함께 그룹화하여 권장사항을 제공하는 근린 방법[21]과 행렬 요인화 기법을 통해 특정 암묵적 요인에 의해 사용자와 제품을 특징짓는 잠재적 요인 방법[9, 17]이 나중에 성공적으로 배치되었다. 두 번째 관점은 통계적 모델에 의존하여 주어진 데이터를 기반으로 사건의 확률을 분류하거나 예측하는 예측 분석에서 나온다[5]. 예측 모델은 선형 및 로지스틱 회귀[26]와 같은 단순 모델을 사용하는 것에서 딥 네트워크를 통합하는 모델로 이동했다. 범주형 데이터를 처리하기 위해, 이 모델들은 1-핫 벡터와 다중-핫 벡터를 추상적 공간에서 조밀한 표현으로 변환하는 임베딩의 사용을 채택했다[20]. 이 추상적인 공간은 추천 시스템에 의해 발견된 잠재 요소의 공간으로 해석될 수 있다. 본 논문에서는 앞에서 설명한 두 가지 관점의 조합에 의해 구상된 개인화 모델을 소개한다. 모델은 [24]에서 제안한 통계적 기법을 사용하여 범주형 데이터를 나타내는 희박한 형상과 다층 지각자(MLP)를 처리한 다음, 이러한 형상을 명시적으로 상호작용한다. 마지막으로, 다른 MLP와의 상호작용을 후처리하여 사건 확률을 찾는다. 
우리는 이 모델을 깊은 학습 권고 모델(DLRM)이라고 부른다. 그림 1. 이 모델의 PyTorch 및 Caffe2 구현은 이 원고의 출판에 대한 시험과 실험을 위해 공개될 것이다.


2 Model Design and Architecture
이 절에서는 DLRM의 디자인에 대해 설명합니다. 우리는 네트워크의 고수준 구성 요소로 시작하여 향후 모델 설계에 대한 함의와 함께 특정 방법으로 함께 조립 된 방법과 이유를 설명하고 모델을 구성하는 하위 수준 연산자와 프리미티브를 특성화하여 미래의 하드웨어 및 시스템 설계.

이 절에서는 DRM의 설계를 설명한다. 네트워크의 높은 레벨의 구성요소부터 시작하여, 미래의 모델 설계에 대한 함축적 의미와 함께 모델을 구성하는 저수준의 연산자 및 원초적 요소를 향후의 하드웨어 및 시스템 설계에 대한 함축적 함축적 함축적 함축적 함축적 함축적으로 특징짓는다.

2.1 Components of DLRM
DRM의 높은 수준의 구성 요소는 초기 모델을 검토하면 더 쉽게 이해할 수 있다. 우리는 완전한 과학 문헌 검토를 피하고 대신 DRM의 두드러진 고차원의 구성요소로 해석될 수 있는 초기 모델에 사용된 네 가지 기술에 초점을 맞출 것이다.


2.1.1 Embeddings
범주형 데이터를 처리하기 위해, 내장들은 각 범주를 추상적인 공간에 밀집된 표현으로 매핑한다. 특히, 각각의 임베딩 룩업은 다음과 같이 임베딩 테이블 W row R mxd의 해당 행 벡터를 얻기 위해 1개의 핫 벡터 ei(i번째 위치는 1이고 다른 위치는 0인 반면 인덱스 i는 i번째 범주에 해당함)를 사용하는 것으로 해석할 수 있다. wT i = e T i W. (1)

더 복잡한 시나리오에서, 임베딩은 또한 여러 항목의 가중치 조합을 나타낼 수 있으며, 다중 핫 벡터(다중 가중치 조합을 나타낼 수 있다.
T = [0, ..., ai1]
,..., aik
, ..., 0), i = i1, ..., ik 및 다른 모든 곳에서 ai 6 = 0인 요소, 여기서 i1, ..., ik는 해당 항목을 색인한다. 따라서 T 포함 조회의 미니 배치는 S = A로 작성될 수 있다는 점에 유의하십시오.
T W(2)
여기서 희소 행렬 A = [a1, ..., at] [20]. DRM은 범주형 형상을 조밀한 표현에 매핑하기 위해 임베딩 표를 이용할 것이다. 그러나 이러한 장식들이 의미 있게 고안된 후에도, 어떻게 그것들을 정확한 예측을 만들어내기 위해 이용될 수 있을까? 이에 답하기 위해 우리는 잠복 요인 방법으로 되돌아간다.

2.1.2 Matrix Factorization
권고 문제의 일반적인 공식에서 일부 제품의 등급을 매긴 사용자의 S 집합이 제공된다는 점을 상기하십시오. i = 1, ..., n 및 j-th 사용자에 대한 벡터 wi ∈ Rd에 의한 i-th 제품을 나타내고자 한다. vj ∈ R d for j = 1, ..., m, m에 의한 모든 등급을 찾기 위해, n과 m은 각각 제품 및 사용자의 총 수를 나타낸다. 보다 엄밀히 말하면, set S는 i번째 제품이 j번째 사용자에 의해 등급을 받았을 때 tuples (i, j) 인덱싱으로 구성된다.

min X
(i,j)∈S
rij − wT
i vj

행렬 인자화 접근방식은 rij ∈ R이 i = 1, ..., m and j = 1, ..., n에 대한 j th 사용자에 의한 i-th 제품의 등급인 위치를 최소화함으로써 이 문제를 해결한다. 그런 다음 WT = [w1, ..., wm] 및 V T = [v1, ..., vn]을 R≈ 제품으로 전체 등급 R = [rij ]의 매트릭스를 근사할 수 있다.
. W와 V는 두 개의 포함 테이블로 해석될 수 있으며, 여기서 각 행은 잠재된 요인 공간의 사용자/제품을 나타낸다2 [17]. 이러한 내장 벡터의 도트 제품은 후속 등급에 대한 의미 있는 예측을 산출하며, 요인화 기계와 DRM 설계에 대한 핵심 관찰을 제공한다.

2.1.3 Factorization Machine
분류 문제에서는 입력 데이터접속 x ∈ Rn부터 대상 라벨 y ∈ T까지의 예측 함수 φ : Rn → T를 정의하고 싶다. 예를 들면 클릭의 존재를 +1로 정의하여 클릭율을 예측할 수 있다. 요인화 기계(FM)는 형태 모형을 정의하여 범주형 데이터를 가진 선형 모형으로 2차 교호작용을 통합한다.
yˆ = b + wT x + x
T
upper(V V T
)x
여기서 V ∈ Rnxd , w ∈ Rn 및 b ∈ R은 d  n을 가진 매개변수이며, 상부는 매트릭스의 엄밀히 상부 삼각형 부분을 선택한다[24].

FM은 희소 데이터를 더 효과적으로 처리하는 매트릭스 계수화에서와 같이 두 번째 순서 상호작용 매트릭스를 잠재 요인(또는 내장 벡터)에 포함시키기 때문에 다항식 커널[4]을 사용하는 지원 벡터 기계와 특히 구별된다. 이것은 선형 계산 복잡성을 산출하고, 고유한 내장 벡터 쌍 사이의 상호 작용만 포착함으로써 2차 상호작용의 복잡성을 상당히 감소시킨다.

2.1.4 Multilayer Perceptrons
동시에, 최근 기계 학습에서 많은 성공이 깊은 학습의 증가 때문이다. 이것들의 가장 기초적인 모델은 다층 지각변동(MLP)으로, 완전 연결(FC)층의 인터리빙 시퀀스와 활성화 함수 σ : R → R 적용 컴포넌트로 구성되는 예측 함수다.
yˆ = Wkσ(Wk−1σ(...σ(W1x + b1)...) + bk−1) + bk
where weight matrix Wl ∈ R
nl×nl−1
, bias bl ∈ R
nl
for layer l = 1, ..., k.
이러한 방법은 더 복잡한 상호작용을 포착하기 위해 사용되어 왔다. 예를 들어, 충분한 매개변수가 주어지면, 충분한 깊이와 폭을 가진 MLP는 데이터를 임의의 정밀도에 맞출 수 있다는 것을 보여주었다[1]. 이러한 방법의 다양성은 컴퓨터 비전과 자연 언어 처리를 포함한 다양한 응용 분야에 널리 사용되어 왔다. MLPerf 벤치마크[19]의 일부로 사용되는 Neural Collaborative Filtering(NCF)[15, 25]은 행렬 인자화에서 내장재 사이의 상호작용을 계산하기 위해 도트 제품이 아닌 MLP를 사용한다.

2.2 DLRM Architecture
지금까지, 우리는 추천 시스템과 예측 분석에 사용되는 다른 모델에 대해 설명하였다. 이제 그들의 직관을 결합하여 최첨단 개인화 모델을 구축해 봅시다.
사용자와 제품을 많은 연속적 및 범주적 특징으로 설명하도록 한다. 범주형 형상을 처리하기 위해, 각 범주형 형상은 행렬 인자화(3)에 사용되는 잠재 인자의 개념을 일반화하면서 동일한 차원의 내장형 벡터로 표현된다. 연속 형상을 처리하기 위해 연속 형상은 내장 벡터(5)와 동일한 길이의 밀도 표현을 생성하는 MLP(아래 또는 밀도 MLP)에 의해 변환된다.

FM(4)에서 제공하는 희소 데이터를 취급하는 직관에 따라 다양한 기능의 2차적 상호작용을 명시적으로 계산하여 선택적으로 MLP를 통해 전달할 것이다. 이것은 모든 임베딩 벡터와 처리된 밀도 형상의 쌍 사이에 도트 제품을 가져가면 된다. 이러한 도트 제품은 원래 처리된 밀도 형상과 연관되어 다른 MLP(상단 또는 출력 MLP)(5)와 사후 처리되어 S자형 함수로 공급되어 확률을 제공한다.
우리는 결과 모델을 그림 1과 같이 DRM이라고 부른다. 우리는 표 1의 PyTorch[23]와 Caffe2[8] 프레임워크에서 DRM에 사용된 일부 연산자를 보여준다.


2.3 이전 모델과 비교
많은 딥러닝 기반 권장 모델[3, 13, 27, 18, 28, 29]은 희박한 특징을 다루기 위해 더 높은 수준의 용어를 생성하기 위해 유사한 기본 아이디어를 사용한다. Wide and Deep, Deep and Cross, DeepFM 및 xDeep예를 들어, FM 네트워크는 더 높은 수준의 상호작용을 체계적으로 구성하기 위한 특수 네트워크를 설계한다. 그런 다음 이 네트워크들은 그들의 특수 모델과 MLP에서 얻은 결과를 합하여 이것을 선형 계층과 S자형 활성화를 통해 전달하여 최종 확률을 산출한다. DRM은 최종 MLP에서 임베딩 쌍 사이에 도트 제품이 생성하는 교차 조건만 고려함으로써 모델의 치수성을 현저하게 감소시키기 위해 요인화 기계를 모방한 구조화된 방식으로 임베딩을 상호 작용한다. 우리는 다른 네트워크에서 발견되는 2차적 순서를 넘어서는 고차적 상호 작용이 필요하지 않을 수 있다고 주장한다.추가 계산/메모리 비용의 가치가 있다.

DRM과 다른 네트워크 사이의 주요 차이점은 이러한 네트워크가 내장형 특징 벡터 및 이들의 교차 용어를 처리하는 방법에 있다. 특히 DRM(및 xDeep)FM [18])은 각 형상 벡터를 단일 범주를 나타내는 단일 단위로 해석하는 반면, 딥과 크로스 같은 네트워크는 형상 벡터의 각 요소를 서로 다른 교차 항을 산출해야 하는 새로운 단위로 취급한다. 따라서, 딥과 크로스 네트워크는 도트 제품을 통해 DRM에서와 같이 다른 형상 벡터의 요소들 사이에서 교차 항을 생성할 뿐만 아니라, 동일한 형상 벡터 내의 요소들 간에 교차 항을 생성하여 더 높은 차원성을 얻을 것이다.

3 Parallelism
현대의 개인화 및 권장 시스템은 방대한 양의 데이터를 활용하기 위해 크고 복잡한 모델을 요구한다. DRM은 특히 매우 많은 수의 매개변수를 포함하고 있는데, 이는 CNN, 변압기 및 반복 네트워크(RN), 생성 네트워크(GAN)와 같은 다른 일반적인 심층 학습 모델보다 훨씬 더 크다. 이것은 몇 주 또는 그 이상의 훈련 시간을 가져온다. 따라서 이러한 문제를 실용적인 차원에서 해결하기 위해서는 이러한 모델을 효율적으로 병렬화하는 것이 중요하다.

앞 절에서 설명한 바와 같이 DRM은 범주형 특징(내장 포함)과 연속적 특징(하위 MLP 포함)을 모두 결합하여 처리한다. 임베딩은 매개변수의 대부분을 기여하며, 각각 여러 GB의 메모리를 필요로 하는 여러 테이블이 있어 DRM 메모리 용량과 대역폭을 많이 사용한다. 장식물의 크기는 데이터 병렬을 사용하는 것을 엄금한다. 왜냐하면 그것은 모든 장치에 큰 내장들을 복제해야 하기 때문이다. 많은 경우에, 이 메모리 제약조건은 메모리 용량 요구사항을 만족시키기 위해 복수의 장치에 걸친 모델 분포를 필요로 한다.

반면에, MLP 매개변수는 메모리는 작지만 크기가 큰 컴퓨팅 양으로 변환된다. 따라서, 데이터 병렬은 다른 기기에서 샘플의 동시 처리를 가능하게 하고 업데이트를 축적할 때만 통신이 필요하기 때문에 MLP에 선호된다. 우리의 병렬화된 DRM은 MLP에 대한 모델 병렬과 MLP에 대한 데이터 병렬주의를 결합하여, MLP에 대한 전방과 후방 전파를 병렬화하면서 내장들에 의해 생성된 메모리 병목 현상을 완화시킬 것이다. 모델과 데이터 병렬은 그것의 구조와 큰 모델 크기의 결과로 DRM의 고유한 요구사항이다. 그러한 결합 병렬은 카페2나 파이토르흐(다른 인기 깊은 학습 프레임워크뿐만 아니라)에서는 지원되지 않으므로 우리는 맞춤형 구현을 설계한다. 우리는 앞으로의 작업에 있어서 그것의 상세한 성과 연구를 제공할 계획이다.

우리의 설정에서, 상단 MLP와 상호작용 운영자는 하단 MLP와 모든 내장으로부터 미니 배치의 일부에 접근해야 한다. 모델 병렬은 기기 간에 내장재를 배포하는 데 사용되었기 때문에, 개인화된 전체 통신[12]이 필요하다. 임베딩 룩업이 끝날 때, 각 장치에는 미니 배치의 모든 샘플에 대해 해당 장치에 상주하는 임베딩 테이블용 벡터가 있으며, 이 벡터는 그림 2와 같이 미니 배치 차원을 따라 분할하여 적절한 장치에 전달해야 한다. PyTorch나 Caffe2 모두 모델 병렬에 대한 기본 지원을 제공하지 않으므로, 임베딩 연산자(nn)를 명시적으로 매핑하여 구현하였다.PyTorch의 경우 Bag, Caffe2의 경우 SparseLengthSum을 서로 다른 장치에 포함. 그런 다음, 나비 셔플 연산자를 사용하여 개인화된 전체 통신 방식을 구현한다. 이 연산자는 결과 내장 벡터를 적절히 잘라 대상 장치로 전송한다. 현재 버전에서는 이러한 전송이 명시적인 복사본이지만, 이용 가능한 통신 기본 사항(예: 올게더 및 송신-레크브)을 사용하여 이를 더욱 최적화하고자 한다.

데이터 병렬 MLP의 경우, 역방향 패스의 매개변수 업데이트는 allreduce3으로 누적되어 동기식으로 각 디바이스[12]의 복제된 매개변수에 적용되므로, 각 디바이스의 업데이트된 매개변수가 매 반복 전에 일관성을 유지할 수 있다는 점에 주목한다. PyTorch에서 데이터 병렬은 nn을 통해 활성화된다.DistributedDataParallel 및 nn.DataParallel 모듈 각 장치에 모델을 복제하고 필요한 종속성으로 할당을 삽입. 카페2에서는 그라데이션 업데이트 전에 알류스를 수동으로 삽입한다.

4 Data
모델의 정확성을 측정하고, 그 전체적인 성능을 시험하고, 개별 사업자의 특성을 파악하기 위해서는, 우리는 구현을 위한 데이터 세트를 만들거나 얻을 필요가 있다. 현재 모델의 구현은 랜덤, 통합 및 공용 데이터 세트의 세 가지 데이터 세트를 제공한다.
이전 두 데이터 세트는 시스템 관점에서 모델을 실험할 때 유용하다. 특히 데이터 스토리지 시스템에 대한 의존성을 제거하면서 즉시 데이터를 생성함으로써 서로 다른 하드웨어 속성과 병목현상을 행사할 수 있다. 후자는 우리가 실제 데이터에 대한 실험을 하고 모델의 정확도를 측정할 수 있게 해준다.

4.1 Random
DRM이 연속 및 범주형 형상을 입력으로 수용한다는 점을 상기하십시오. 전자는 numpy.random package rand 또는 기본 파라미터가 있는 randn 호출과 동일한 분포 또는 정규 분포(Gaussian)를 사용하여 난수 벡터를 생성하여 모델링할 수 있다. 그런 다음 각 행이 미니 배치의 요소에 해당하는 매트릭스를 생성하여 입력의 미니 배치를 얻을 수 있다.

범주형 특성을 생성하려면 주어진 다중 핫 벡터에 0이 아닌 요소를 몇 개 포함할지 결정해야 한다. 벤치마크는 이 숫자를 범위4[1, k] 내에서 고정하거나 무작위로 지정할 수 있도록 한다. 그런 다음, 우리는 [1, m] 범위 내에서 상응하는 정수 지수 수를 생성한다. 여기서 m은 (2)에서 포함된 W 행의 수입니다. 마지막으로, 검색의 미니 배치를 생성하기 위해 위의 지수를 연결하여 각 개별 조회를 길이(SparseLengthsSum) 또는 간격띄우기(nn)로 표시한다.EmbeddingBag) 5.

4.2 Synthetic
범주형 특징에 해당하는 지수의 사용자 정의 생성을 지원하는 데에는 여러 가지 이유가 있다. 예를 들어, 우리의 응용 프로그램이 특정 데이터 세트를 사용하지만 우리는 프라이버시를 위해 그것을 공유하고 싶지 않다면, 우리는 분포를 통해 범주형 특징을 표현하도록 선택할 수 있다. 이는 잠재적으로 연합 학습과 같은 응용 프로그램에 사용되는 프라이버시 보존 기술의 대안으로 작용할 수 있다[2, 10]. 또한, 우리가 기억의 행동을 연구하는 것과 같은 시스템 구성요소를 연습하고 싶다면, 우리는 합성 추적 내에서 원래의 추적에 대한 접근의 근본적인 영역을 포착하고 싶을 것이다.

이제 통합 데이터 세트를 어떻게 사용할 수 있는지 설명해보자. 단일 범주형 형상에 대한 검색 포함에 해당하는 인덱스의 흔적이 있다고 가정한다(그리고 모든 형상에 대한 프로세스를 반복). 이 추적(예1)에 반복 접속 사이의 고유 접근과 빈도를 기록하고 [14]에서 제안한 대로 합성 추적(예: 2)을 생성할 수 있다.

참고: 지금까지 본 고유한 액세스 수까지의 스택 거리만 생성할 수 있으므로 s는 Alg. 2. 고정 액세스 수를 고려할 때 입력 트레이스가 길수록 Alg. 1에서 해당 액세스에 할당될 확률이 낮아져 달성 시간이 길어진다.e. 2의 전체 배포 지원 이 문제를 해결하기 위해, 우리는 고유 접근에 대한 확률을 최소 임계값까지 높이고 지원을 조정하여 일단 모든 것이 확인되면 그것에서 고유한 접근성을 제거한다. 원본 및 합성 추적을 기반으로 한 확률 분포 p의 시각적 비교는 그림 3에 나타나 있다. 우리의 실험에서 원래와 조정된 합성 추적은 유사한 캐시 적중률/누락률을 산출한다.

예 1과 2는 보다 정확한 캐시 시뮬레이션을 위해 설계되었지만, 확률 분포를 사용하여 원하는 속성으로 합성 추적을 생성하는 방법에 대한 일반적인 개념을 보여준다.

4.3 Public
추천 및 개인화 시스템에 사용할 수 있는 공용 데이터 세트는 거의 없다. Crito AI Labs Ad Caggle6 및 Terabyte7 데이터 세트는 광고 CTR 예측을 위한 클릭 로그로 구성된 오픈 소스 데이터 세트다. 각 데이터 세트에는 13개의 연속 형상과 26개의 범주형 형상이 포함되어 있다. 일반적으로 연속 형상은 간단한 로그 변환 로그(1 + x)로 사전 처리된다. 범주형 형상은 라벨이 없는 범주형 형상 또는 라벨이 0 또는 NULL로 매핑된 해당 포함 색인에 매핑된다.

Criteo Add Caggle 데이터 세트는 7일 동안 약 4,500만 개의 샘플을 포함하고 있다. 실험에서, 일반적으로 7일은 검증과 시험 세트로 나뉘며, 첫 6일은 훈련 세트로 사용된다. Crito Ad Terabyte 데이터 세트는 24일에 걸쳐 샘플링되며, 여기서 24일은 검증 및 테스트 세트로 분할되고 처음 23일은 교육 세트로 사용된다. 각 날짜의 샘플 수는 거의 동일하다는 점에 유의하십시오.

5 Experiments
이제 DRM의 성능과 정확성을 설명해보자.
모델은 PyTorch와 Caffe2 프레임워크에서 구현되며 GitHub8에서 사용할 수 있다. 모델 파라미터와 인덱스에 각각 fp32 부동점과 int32(Caffe2)/int64(PyTorch) 유형을 사용한다. 실험은 그림 4에 나온 Open Compute Project9 를 통해 공개적으로 이용할 수 있는 듀얼 소켓 Intel Xeon 6138 CPU와 8개의 Nvidia Tesla V100 16GB GPU로 빅 분지 플랫폼에서 수행된다.

5.1 Model Accuracy on Public Data Sets
우리는 Crito Add Kaggle 데이터 세트에 대한 모델의 정확성을 평가하고 광범위한 튜닝 없이 DRM의 성능을 DCN(Deep and Cross Network)과 현재 상태를 비교한다[27]. DCN은 동일한 데이터 세트에서 포괄적인 결과를 얻는 몇 안 되는 모델 중 하나이기 때문에 DCN과 비교한다. 이 경우 모델은 데이터 세트에 존재하는 형상의 수를 수용할 수 있도록 크기가 조정된다는 점에 유의하십시오. 특히 DRM은 각각 512, 256, 64개의 노드를 가진 3개의 숨겨진 레이어로 구성된 밀도 형상을 처리하기 위한 하단 MLP와 512와 256개의 노드를 가진 2개의 숨겨진 레이어로 구성된 상위 MLP로 구성되어 있다. 반면 DCN은 6개의 크로스 레이어와 512와 256개의 노드를 가진 딥 네트워크로 구성되어 있다. 16의 내장 치수를 사용한다. 이 경우 약 540M 파라미터로 DRM과 DCN이 모두 생성된다는 점에 유의하십시오.

우리는 SGD와 Adagrad 최적기를 사용하는 두 모델에 대한 전체 단일 교육 시기의 교육(고결) 및 검증(파손) 관련 정보를 모두 계획한다[6]. 정규화는 사용되지 않는다. 이 실험에서 DRM은 그림 5와 같이 약간 더 높은 훈련 및 검증 정확도를 얻는다. 우리는 이것이 모델 하이퍼 파라미터의 광범위한 조정 없이 이루어졌다는 것을 강조한다.

5.2 단일 소켓/장치의 모델 성능
단일 소켓 장치에서 모델의 성능을 프로파일링하기 위해, 우리는 8개의 범주형 특징과 512개의 연속 형상을 가진 표본 모델을 고려한다. 각 범주형 특성은 벡터 치수 64로 1M 벡터가 있는 내장형 표를 통해 처리되며, 연속 형상은 치수 512의 벡터로 조립된다. 맨 아래 MLP에는 두 개의 층이 있고, 맨 위 MLP에는 네 개의 층이 있다. 2048K 랜덤으로 생성된 샘플이 1K 미니 배치 10으로 구성된 데이터 세트에 이 모델을 프로파일링하십시오.

Caffe2의 이 모델 구현은 CPU에서 약 256초, GPU에서 62초 만에 실행되며, 그림 6에 나타난 개별 운영자의 프로파일링을 통해 예상한 대로 대부분의 시간이 임베디드 룩업과 완전히 연결된 레이어를 수행하는 데 소요된다. CPU에서 완전히 연결된 계층은 계산에서 상당한 부분을 차지하는 반면, GPU에서는 거의 무시할 수 있다.

본 논문에서는 범주형 데이터를 활용한 소설 깊은 학습 기반의 추천 모델을 제안하고 오픈소싱하였다. 권고와 개인화 시스템이 오늘날에도 산업계 내에서 깊이 있는 학습의 실질적인 성공을 주도하고 있지만, 이러한 네트워크는 학계에서 계속해서 거의 주목을 받지 못하고 있다. 주정부-종종적인 권고 시스템과 그 공개 소스 구현에 대한 상세한 설명을 제공함으로써, 우리는 이 등급의 네트워크가 추가적인 알고리즘 실험, 모델링, 시스템 공동 설계 및 벤치마킹의 목적을 위해 접근 가능한 방법으로 제시하는 고유한 문제에 관심을 끌기를 바란다.
