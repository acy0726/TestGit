PERSONALIZED EXPLANATION FOR MACHINE LEARNING: A CONCEPTUALIZATION



기계 학습과 인공지능과 같은 관련 분야의 설명은 기계 학습 모델과 그 결정을 인간이 이해할 수 있게 만드는 것을 목표로 한다. 기존의 연구는 설명을 개인화하는 것이 이해가능성을 향상시키는 데 도움이 될 수 있다는 것을 암시한다. 본 작품에서는, 프라이버시와 지식의 도출과 같은 다른 영역의 기계 학습 설명, 개인화(기계 학습에 있어서의) 및 개념과 기술에 관한 이전의 작업을 바탕으로 문제를 정의하고 구조화함으로써, 개인화된 설명의 개념화를 도출한다. 우리는 개인화 과정에 사용된 설명자 데이터의 분류와 이 데이터를 수집하기 위한 방법을 설명한다. 우리는 또한 개인화로 수정할 수 있는 세 가지 주요 설명 속성, 즉 복잡성, 의사결정 정보 및 표시를 식별한다. 우리는 또한 추가적인 desiderata와 개인화된 설명의 질을 정량화하는 조치를 도입함으로써 설명에 대한 기존의 작업을 강화한다.

인공 지능과 같은 기계 학습 및 관련 분야에서의 설명은 기계 학습 모델과 그 결정을 인간이 이해할 수있게 만드는 것을 목표로합니다. 기존 연구에 따르면 설명을 개인화하면 이해력이 향상 될 수 있습니다. 이 작업에서는 기계 학습 설명, 개인화 (기계 학습) 및 사생활 및 지식 추출과 같은 다른 영역의 개념 및 기술에 대한 사전 작업을 기반으로 문제를 정의하고 구조화하여 개인화 된 설명의 개념을 도출합니다. 우리는 개인화 과정에서 사용되는 설명자 데이터의 범주화와이 데이터를 수집하는 방법을 설명합니다. 우리는 또한 개인화를 수정할 수있는 세 가지 핵심 설명 속성, 즉 복잡성, 결정 정보 및 표현을 확인합니다. 또한 개인화 된 설명의 질을 정량화하기위한 추가 요구 사항과 조치를 소개함으로써 기존의 설명 작업을 향상시킵니다.







컴퓨터 학습 (ML)과 인공 지능과 같은 관련 분야와 같은 데이터로부터 지식을 추출하는 기술은 지난 몇 년 동안 급속도로 중요성이 커지고 있습니다. 컴퓨터 비전, 음성 인식 및 자연어 처리 (Goodfellow et al., 2016)와 같은 여러 분야에서 인간 의사 결정을 지원하거나 대체하는 기술을 사용하는 자동 의사 결정이 점점 더 중요 해지고 있습니다. 이것은 부분적으로 깊은 학습과 같은 복잡한 기술의 출현과 개선에 기반을두고 있으며, 이는 여러 문제에 대한 최첨단 기술을 추진하고 있습니다 (Goodfellow et al., 2016). 불행히도, 복잡한 기술은 종종 사람들에게 이해하기 어렵고, "블랙 박스"라는 칭호를 얻습니다. 결과적으로 연구는 철저한 질적 이해없이 성과 척도를 비교하는 경험적 평가에 의해 좌우되는 경우가 많습니다. 또한 이러한 기술을 사용하는 시스템은 종종 놀라운 오류가 발생할 수 있기 때문에 신뢰할 수없는 것으로 간주됩니다. 인간이 할 수없는 방식으로 속일 수있다 (Nguyen et al., 2015). 이러한 사실은 더 깊은 이해를 가능하게하는 설명의 필요성을 뒷받침합니다. 설명에 대한 관심은 법률로 인해 증가했습니다. 유럽 ​​의회는 2018 년 일반 정보 보호 규정 (General Data Protection Regulation, GDPR)을 도입했습니다. 이는 자동 의사 결정과 관련된 결과에 대해 개인이 "관련된 논리에 대한 의미있는 설명"을 할 수있는 권한을 부여합니다.

의미 있고 이해하기 쉬운 설명을 얻기 위해, ML에 관한 문헌은 이미 ML의 기술적 측면(Adadi and Berrada, 2018; Doshi-Velez and Kim, 2017; Doshilovich et al., 2018; Kirsch, 2017; Ras et al., 2018)보다는 인간에 초점을 맞출 필요성을 표현했다. 개인에 맞춘 설명(개인화된 설명)의 필요성도 강조됐다. 설명을 의도하는 사람(또는 설명자 그룹)은 자신에 대한 데이터(설명자 데이터)를 제공해야 한다. 원시 데이터에서 설명자에 대한 의미 있는 정보를 얻기 위해서는 정교한 지식 추출과 선호도 도출이 필요할 수 있다. 설명자 데이터와 ML 모델의 비개인적 설명에 사용된 데이터는 개인화된 설명 방법에 대한 입력으로 사용된다.
개인화된 설명 방법은 ML 모델의 내부, 결정(예: 예측 클래스 라벨) 및 설명자 데이터 및 파생 정보와 조합하여 훈련(및 테스트) 데이터를 분석할 수 있다. 예를 들어, 두 모델에서 발견된 특징을 식별하고 비교함으로써 설명자의 의사결정 프로세스의 모델을 추출하고 ML 모델과 일치시킬 수 있다.


그러나 기존의 문헌은 개인화가 ML 모델에 의해 수행된 과제의 일부였을 때 개인화된 설명의 개념을 거의 독점적으로 채택했다. 예를 들어, 제출된 제품 리뷰와 같은 개인에 대한 정보를 활용하여 예측을 도출하는 권고 시스템에서는, 개인화된 설명의 아이디어가 표현되었다(Zang et al., 2014). 따라서 먼저 해설자로부터 데이터를 수집한 다음 이를 활용하여 설명을 개선하려는 생각은 기존 문헌에 크게 존재하지 않았다. 이 작업은 두 단계를 모두 논의함으로써 이 격차를 좁히려고 한다. 우리는 ML에 대한 설명으로 개인화의 현재 상태에 대한 개요를 제공한다. 우리는 개인화된 설명, 개인화할 수 있는 치수, 개인으로부터 정보를 얻을 수 있는 것과 방법, 그리고 이 정보를 어떻게 사용자 정의에 활용할 수 있는지에 대한 프레임워크를 제공한다. 마지막으로, 우리는 개인화된 설명 방법을 어떻게 평가할 것인지에 대해서도 논의한다. 우리는 "기계학습의 설명", "기계학습에서의 개인화" 및 기타 영역에서 기존 문헌을 조사·합성함으로써 그렇게 한다. 본 논문의 구조는 다음과 같다: 방법론(제2절), 배경 정보 제공(제3절), 개인화된 설명 개념화(제4절) 후, 제5절의 설명자 데이터에 대해 상세히 설명하고, 마지막으로 제6절의 개인화된 설명 방법을 논의하고, 제7항의 평가 방법을 제시한다.


2.방법론
개념화를 개발하기 위해, ML(설명, 개인화 및 공정성), 개인화, 프라이버시, 지식 엘리시테이션의 동료 연구자들이 실시한 체계적인 문헌 검토에서 종합한 개념, 방법 및 아이디어를 활용, 적용하였다. ML에서의 개인화된 설명은 다른 많은 분야에 의존하는 신흥 분야이기 때문에, 서술 문학 검토와 같은 질적 검토 접근에 적합해 보인다(King and He, 2005). 스웨덴 스톡홀름-웁살라, 유럽 정보 시스템 회의(ECIS2019). 3 재현성 더 구조화된 접근법이 선호된다. 웹스터와 왓슨(2002년)의 방법을 조정했다. 즉, 앞뒤 검색을 수행하여 개념 매트릭스를 도출하였으나 문학 선택 과정에서 이탈하였다. 우리는 IEEE Xplore와 AIS와 ACM 라이브러리와 같은 정보 시스템과 컴퓨터 과학에서 확립된 온라인 데이터베이스를 활용했다. ML의 발전은 겉보기에는 유명해 보이는 저자들이 컨퍼런스 절차가 마련되기 전에 platform 플랫폼 연도에 관한 기사를 발표하면서 매우 빠르다. 많은 기사들이 저널에 전혀 실리지 않는다. 따라서 독자들에게 가장 최신의 시각을 주기 위해, 우리는 신중하게 검토한 후에 after의 기사뿐만 아니라 회의 기사도 포함시켰다. 키워드로서 우리는 위에 열거된 영역 이름(예: 개인화, ML에서의 설명)을 활용했다. "조사"와 "검토"를 부가하여 범위를 제한했다. 그 결과를 위해 전방과 후방 검색을 이용해 검색을 확대했다. 우리는 관련 작업을 걸러내기 위해 제목과 추상화를 읽는다. 우리의 초점은 "ML의 개인화된 설명"의 모든 관련 영역에서 역사적 개요를 제공하는 것이 아니라 최근의 개발을 포함한 개념화를 도출하는 것이었다. 특히, 매우 급속한 개발 중에 있는 ML의 설명 방법에 대해서는, 인용, 조사에서의 참조, 파생된 개념에 근거한 개인화에 대한 적합성에 근거하여 가장 두드러진 기법을 선택하는 것에 한정되었다. 그러나, 우리는 좀 더 자세한 개요를 위해 조사를 지적한다. 이렇게 기사가 좁혀지는 것은 우리 일의 한계다.


개념화를 개발하기 위해, ML(설명, 개인화 및 공정성), 개인화, 프라이버시, 지식 엘리시테이션의 동료 연구자들이 실시한 체계적인 문헌 검토에서 종합한 개념, 방법 및 아이디어를 활용, 적용하였다. ML에서의 개인화된 설명은 다른 많은 분야에 의존하는 신흥 분야이기 때문에, 서술 문학 검토와 같은 질적 검토 접근에 적합해 보인다(King and He, 2005). 스웨덴 스톡홀름-웁살라, 유럽 정보 시스템 회의(ECIS2019). 3 재현성 더 구조화된 접근법이 선호된다. 웹스터와 왓슨(2002년)의 방법을 조정했다. 즉, 앞뒤 검색을 수행하여 개념 매트릭스를 도출하였으나 문학 선택 과정에서 이탈하였다. 우리는 IEEE Xplore와 AIS와 ACM 라이브러리와 같은 정보 시스템과 컴퓨터 과학에서 확립된 온라인 데이터베이스를 활용했다. ML의 발전은 겉보기에는 유명해 보이는 저자들이 컨퍼런스 절차가 마련되기 전에 platform 플랫폼 연도에 관한 기사를 발표하면서 매우 빠르다. 많은 기사들이 저널에 전혀 실리지 않는다. 따라서 독자들에게 가장 최신의 시각을 주기 위해, 우리는 신중하게 검토한 후에 after의 기사뿐만 아니라 회의 기사도 포함시켰다. 키워드로서 우리는 위에 열거된 영역 이름(예: 개인화, ML에서의 설명)을 활용했다. "조사"와 "검토"를 부가하여 범위를 제한했다. 그 결과를 위해 전방과 후방 검색을 이용해 검색을 확대했다. 우리는 관련 작업을 걸러내기 위해 제목과 추상화를 읽는다. 우리의 초점은 "ML의 개인화된 설명"의 모든 관련 영역에서 역사적 개요를 제공하는 것이 아니라 최근의 개발을 포함한 개념화를 도출하는 것이었다. 특히, 매우 급속한 개발 중에 있는 ML의 설명 방법에 대해서는, 인용, 조사에서의 참조, 파생된 개념에 근거한 개인화에 대한 적합성에 근거하여 가장 두드러진 기법을 선택하는 것에 한정되었다. 그러나, 우리는 좀 더 자세한 개요를 위해 조사를 지적한다. 이렇게 기사가 좁혀지는 것은 우리 일의 한계다.


3 배경
개인화는 전자상거래, 컴퓨터 과학, 인지 과학과 같은 여러 분야(팬과 포올, 2006년)에서 연구되었다. 우리의 작업은 사용자 모델링 동안 인지 과학, 즉 "행동 관찰에 기초한 사용자의 목표, 관심, 선호 및 지식에 대한 가정"을 포함하지만, 사용자 모델을 IT 시스템에 구현하는 것에 관한 한, 즉 다음과 같은 플랫폼을 제공한다. "개별화된 정보의 유입·유출을 지원한다"(Fan and Poole, 2006). 개인화하려면 선호도나 업무지식과 같은 정보를 얻어야 한다. 특히 구두 또는 글로 표현하기 어려운 암묵적 지식을 추출하기 위해서는 특별한 도출 기술이 필요할 수 있다(Dieste and Juristo, 2011).
ML에서의 개인 설정은 두 가지 방법으로 발생한다. ML은 개인화를 위한 수단으로 사용되어 왔지만, 개인화 자체에도 적용되어 왔다. 전자의 예로는 추천자 시스템을 위한 ML 알고리즘(Cung et al., 2016), 웹 개인화 및 검색(Chen and Chau, 2004)이 있다. ML의 개인화에는 대화형 ML(Amshi et al., 2014; Kulesza et al., 2015) 작업이 포함되며, 여기에는 ML 지식이 거의 없는 잠재적인 도메인 전문가가 참여하는 반복 설계 프로세스를 사용하여 ML 모델을 개선하고자 한다. 이와는 대조적으로, 개인화 설명은 설명 자체를 개인화하는 것을 말한다. "설명하다"는 것은 "명료하게 하거나 이해하기 위해" ("설명", 2018)를 의미한다. "해석"과 관련된 용어는 "해설" ("해석", 2018년)의 의미를 설명하거나 말하기 위한"로 정의될 수 있다. 설명은 다음과 같은 질문에 대한 답을 찾고 있다. 예를 들어, 무엇, 왜, 왜, 만약, 그리고 어떻게 해야 하는가(Lim et al., 2009). 그레고르와 벤바사트(1999)는 다음과 같은 설명 유형을 제안했다: i) 추적 또는 추론, ii) 정당성 또는 지원, ii) 통제 또는 전략, iv) 용어. 그 문헌은 용어를 사용하는 데 있어서 간결하지 않다. 우리는 그 결과를 이해하는 것보다 ML 결과의 의미에 덜 관심이 있기 때문에 "설명"이라는 용어를 선호한다. Huysmans 등(2011년)의 ML 설명에 대한 이전의 연구는 종종 의사결정 나무와 같이 쉽게 설명할 수 있는 것으로 간주되는 모델을 조사했다. 보다 복잡한 ML 모델의 경우, 최근 많은 양의 기법이 개발되었다(Guidotti et al., 2018; Ras et al., 2018).


4. 기계 학습에서 개인화 된 설명
ML에서 개인화 된 설명은 도입부에서 설명한대로 ML 모델과 개인을 대상으로 한 결정에 대한 설명을 유도하는 것을 의미합니다. 이해를 깊게하기 위해 개인화 된 설명에 대한 개요를 설명하고 개인화 및 설명 작업을 기반으로하는 핵심 개념을 소개합니다. 그런 다음 개인화 된 설명에 대한 기존 작업을 특성화하기 위해이를 사용하여 건전성 및 완전성 개념을 테스트합니다.


4-1 개인화 된 설명의 요구 사항
설명 방법에 대한 기존 요구 사항은 개인화 된 설명에도 적용됩니다. 정보 제공자의 정보 획득을위한 노력뿐만 아니라 프라이버시와 같은 추가적인 측면들도 적합하다.
 충실도 (Fidelity) - 설명이 모델의 입출력 매핑과 일치하는 정도 (Guidotti et al., 2018; Ras et al., 2018)
 일반화 가능성 - 설명 방법을 적용 할 수있는 모델의 범위 (Ras et al., 2018)
 설명력 - 설명이 대답 할 수있는 질문의 범위 (Ras et al., 2018)

 해석 가능성 - 설명이 인간이 이해할 수있는 정도 (Guidotti et al., 2018). Fürnkranz et al. (2018)은 설명자의 능력 (객관성)과 설명의 수용 가능성 (주관적 척도)의 객관적 척도를 구별한다.

 노력 - 설명의 해석에 필요한 노력은 물론 개인화에 필요한 추가 데이터를 제공하기 위해 개인이 수행해야하는 노력. 후자는 예를 들어 설명의 복잡성에 달려있다. 데이터 수집에 대한 노력은 개인화 된 설명을 얻기위한 목적으로 만 수집 된 데이터를 나타냅니다. 따라서, 피 수속자에 관한 데이터가 이미 이용 가능하다면, 예를 들어. 설명 할 ML 모델에 대한 훈련 데이터의 일부로 노력은 제로입니다. explainee에 대한 노력은 몇 가지 간단한 질문에 답하는 것부터 신중한 분석을 바탕으로 제안 된 설명에 대한 피드백을 반복적으로 제공하는 것까지 다양합니다.

 개인 정보 - 피 수속자의 데이터를 수집, 저장 및 사용하는 정도. 정보가 "적"에게 사용 가능 해지면 개인 정보 보호가 핵심 관심사입니다. 악의적 인 당사자. 그러한 경우, 익명의 데이터 만 손상된 경우에도 개인 정보가 침해 될 수 있습니다 (de Montjoe et al., 2015). 설명자에 대한 정보는 사용자의인지 능력을 결정할 수있는 IQ 또는 사용자가 선호하는 설명 방법을 얻는 것과 같이 덜 민감한 것과 같이 매우 민감합니다.

 공정성 - 설명이 평등 한 정도 (Binns, 2017; Kusner et al, 2017). 공평성에 대한 개념은 다면적이지만 가능한 목표는 각 개인에 대해 동일한 품질 (충실도, 일반화 가능성, 해석 가능성, 노력)에 대한 설명을 제공하는 것입니다

4-2 개념화 
우리는 설명 방법, 개인화 가능한 설명 속성, 데이터 및 정보 수집, 개인화 세분화, 개인화 자동화 등 5가지 개념을 소개한다. 처음 두 개념은 ML 설명에 기초하고, 나머지 세 개념은 개인화에 기초한다. 우리는 개인화된 설명을 위한 다른 방법을 설명하는 네 번째 차원 "어떻게?"를 추가함으로써 팬과 포올의 (2006) 카테고리("무엇, 누구에게, 누가 개인화하는가?")를 확장한다.
개인화 가능한 설명 속성은 사용자 정의할 수 있는 설명, 즉 설명자 데이터를 기반으로 조정할 수 있는 설명의 특성이다. 아래에서 세 가지 주요 설명 속성을 확인했다.

 복잡성 – 설명의 요소 크기 또는 수(예: 규칙 길이 또는 의사결정 트리 깊이) 및 설명에 제시된 특징 간의 관계(예: 상관 관계(Paulheim, 2012) 또는 접속사(Fürnkranz et al., 2018)를 가리킨다.

 의사결정 정보의 우선순위화 - 설명에 표시할 정보의 선택을 말한다.

여기에는 특징의 선택, 그들의 관계 또는 예가 포함된다. 형상공간과 입력공간에 적용할 수 있다. 전자는 특징 또는 특징 관계의 하위 집합을 사용하여 설명을 구성하여 우선 순위를 정한다. 후자는 설명을 생성하기 위해 사용된 사례의 하위 집합을 가리킨다. 예를 들어, 수천 건의 환자를 모범적으로 진단하는 가상의 질병 진단 방법. 소아과 의사에게 특정 환자 사례의 진단을 설명하기 위해, 예를 사용하는 개인화된 설명은 성인보다 어린이의 환자 사례를 선택할 수 있다.

 프리젠테이션(Presentation) – 강도를 나타내기 위한 숫자와 색상 간의 선택 또는 의사결정 규칙을 제시하기 위한 자연어 또는 논리 표현 간의 선택과 같은 설명의 프리젠테이션 양식을 가리킨다.

설명 방법은 결과에 따라 분류할 수 있다(Molnar, 2018). 설명 방법의 결과는 설명 전략과 표현의 다양성으로 인해 개인화가 수행되는 방법에 영향을 미친다. 다음 네 가지 방법을 문헌에서 각색한다(예. 2018년, 아다디와 베라다; 립톤, 2017년, 몰나르, 2018년, 라스 외, 2018년):

 특징 속성 – 각 특징이 의사결정에 미치는 영향(예: 특징 중요성)을 지적한다. 특징 귀속은 예를 들어 신경망의 두 층 사이의 모델 중간 구성요소 사이의 관계를 설명할 수 있다. 귀속방법은 각 기여자가 귀속목표에 어떻게 영향을 미치는지 지적한다.

 예제 기반 – 모델의 동작을 설명하기 위한 예로서 데이터 인스턴스 반환 데이터 세트(예: 특정 대상 인스턴스 또는 대표 인스턴스) 또는 새로 생성(예: 반사실적 역할을 하기 위해 교란됨) 중에서 선택할 수 있다.

 모델 내부 – 의사결정 트리의 구조, 회귀 모델 또는 신경 네트워크의 형상 시각화 등 모델의 내부 표현 반환.

 대체 모델 – 대상 블랙박스 모델에 가까운 본질적으로 해석 가능한 투명 모델을 반환한다. LIME (Ribeiro 등, 2016). 이 모델은 다른 설명 방법, 즉 형상 속성, 예제 기반 또는 모델 내부 정보를 사용하여 해석된다.

데이터 및 정보 수집은 설명자의 경우 사용자로부터 데이터 및 정보를 얻는 방법을 나타낸다. 정보는 사용자가 작업을 해결하는 방식과 같은 지식 또는 디스플레이에서 선호하는 색상과 같은 사용자 선호도를 나타낼 수 있다. 암시적 정보 수집은 설명이 필요한지 여부에 관계없이 획득한 정보를 말한다. 즉, 이 정보는 예를 들어 권장 시스템(Zhang 및 Chen, 2018)에서 ML 모델의 훈련 데이터의 일부라는 것이다. 이와는 대조적으로, 명확한 정보 수집, 정보는 훈련 데이터 수집과 분리될 수 있는 프로세스를 사용하여 획득된다.

개인화 세분화는 "개인화할 대상" 즉, 개인 또는 특정 개인의 범주에 초점을 맞춘다. 사회적 정체성에 대한 조사 결과는 사람들이 특정 상황에서 사회 집단과 관련된 가치와 우려에 따라 더 많이 행동할 수 있다는 것을 나타낸다. 분류는 개인화의 조잡한 형태일 수 있다. 예를 들어, 우리는 전문지식과 관련된 다른 차원을 평가하고 각 차원을 따라 맞춤화하는 대신에 사용자를 전문가나 비전문가들로 간단히 분류할 수 있다.

개인화 자동화는 "개인화를 하는 사람"(Fan and Poole, 2006), 즉 설명자가 수행하는 수동 개인화 또는 설명을 제공하는 시스템에 의한 자동 개인화에 초점을 맞추고 있다. 수동 개인 설정은 설명 매개변수를 능동적으로 설정하는 설명자에 해당한다(예: 시각화할 특징의 수 선택).

우리는 우리의 개념화에 대한 대안이 있다는 것을 인정한다. 예를 들어, (Molnar, 2018), (Adadi 및 Berrada, 2018; Lipton, 2017; Ras et al., 2018)를 제외하고, 최근의 연구에서 설명 방법을 분류하는 여러 가지 옵션이 있다. 반사실적이고 대조적인 설명(Miller, 2018년)을 포함한 "설명 유형"의 개념을 추가할 수도 있다. 로컬 및 전역 해석성(Guidotti et al., 2018) 및 설명 목적(Ras et al., 2018)과 같은 기타 특성이 추가될 수 있다. 그러나, 그것들은 또한 주어진 것처럼 취급될 수도 있다. 그것들은 직무에 근거하여 암묵적일 수 있으며, 따라서 개인화의 대상이 될 수 없다. 게다가, "설명 유형"은 우리의 프레임워크를 사용하여 개인화할 수 있다. 예를 들어, "결정 정보의 우선순위화"는 설명자와 관련된 반사실적 설명을 선택함으로써 개인화된 반사실적 설명을 지원하는 한편, 예제 기반 설명과 같은 설명 방법은 반사실적 설명을 구현하는 것을 지원한다.



4-3 기존 작업의 분류
우리는 섹션 4.2의 개념과 관련하여 기존 작업을 평가한다. 요약은 표 1에 나와 있다.

표 1 이전 작업은 ML에서 개인화를 위한 개념을 사용하여 분류되었다.  기호는 개념이 적용되었음을 나타낸다. ()는 어떤 종이가 분류의 한 구성원만을 다룬다는 것을 나타낸다.

개인별 설명 특성과 관련하여 복잡성에 대해 두 가지 조작이 관찰된다. 즉 형상 간 크기와 상호작용(Fürnkranz 등, 2018; Narayan 등, 2018). 전자는 규칙 길이 또는 나무 깊이와 같은 측정치를, 후자는 분리 또는 연결과 같은 상호작용을 가리킨다. 우선 순위에 따른 특징에 대한 조정은 (Ross et al., 2017)에 제시된 작업을 제외하고 주로 추천자 시스템에 대한 설명에 따라 수행된다. 프레젠테이션 조정의 경우, 사전 작업에서는 텍스트와 같은 설명 프리젠테이션을 그래픽(Chen 등, 2018; Quijano-Sanchez 등, 2017)과 자연어 텍스트가 있는 워드 태그(Chang 등, 2016년)를 비교했다.
우리는 보다 상세하고 포괄적인 치료를 위해 Adadi 및 Berrada(2018), Guidotti 등(2018), Ras 등(2018), Zhang 및 Chen(2018)의 조사를 참조하기 위해 중요한 설명 방법의 하위 집합만 열거했다. 설명 방법의 관점에서, 대다수의 방법은 특징 귀속을 유익성 방법(예를 들어)을 통한 설명으로 사용한다. Chen 등, 2016; Montavon 등, 2018; Zhang 등, 2018) 및 특징 중요도 값(Lundberg 및 Lee, 2017). 예제 기반 설명은 예를 들어 등급 프로토타입(Li 등, 2017) 또는 가장 영향력 있는 훈련 데이터(Koh 및 량, 2017)와 같은 다른 예를 생성한다. 모델 내부 설명에는 의사결정 나무(Lim et al., 2009)의 의사결정 규칙 제시 또는 신경 네트워크의 뉴런 시각화(Olah et al., 2018)가 포함된다. LIME(Ribeiro et al., 2016)과 같은 방법의 서지컬 모델을 다른 설명 방법, 즉 특징 귀속, 예제 기반 및 모델 내부 방법을 사용하여 설명할 수 있다. 예를 들어, 의사결정 트리를 대리 모델로 선택한 경우, 특성 속성으로 설명할 수 있다.
암시적 정보 수집은 추천자 시스템에서 흔히 볼 수 있다(창 외, 2016; Chen 외, 2018; Quijano-Sanchez 외, 2017; Zhang 외, 2014). 한편, 대화형 설명 인터페이스(Olah 등, 2018; Sokol 및 Flach, 2018)는 명시적 정보 수집으로 볼 수 있는 설명자의 수동 조정을 통합한다. ML 설명의 다른 작업에서는 설명 해석성을 개선하기 위해 인간 피험자의 피드백을 사용했다. 예를 들어, 전문가의 설명을 추가 모델 제약 조건으로 사용(Ross et al., 2017). 레이지 외 연구진(2018년)은 설명을 위해 사용자에게 복수의 모델을 평가해 줄 것을 요청했다. 사용자는 과제 해결, 즉 제공된 설명에 근거한 이미지 분류를 배우도록 되어 있었다. 사용자들이 가장 정확하게 예측하는 결과를 초래한 설명을 제공하는 모델이 선택되었다. 여러 작품들이 어떤 형태로든 개성을 언급하고 있다. 그룹 개인화는 대부분 범주의 한 멤버에 대해서만 수행된다. 예를 들어, 다음에 대한 방법을 평가한다. 
ML(Ribeiro et al., 2016) 또는 도메인 전문가(Wu et al., 2018). 이와는 대조적으로, Lim 등. (2009)는 설명 방법에 대한 사전 지식으로 설명자를 구분하며, 퀴자노-산체스 외 (2017)은 설명자 범주 중 하나로 성격을 사용한다. 개별 개인화를 다루는 사람들에 대해서는, i) 수동 개인화만 허용하거나 ii) 그것들은 추천자 시스템 설명이다.
수동 개인화는 설명 인터페이스(Olah 등, 2018a; Sokol 및 Flach, 2018)를 통해 활성화되거나 베이시안 프리어의 통합이 허용된다(Wang 등, 2016). 추천자 시스템에 대한 설명은 업무의 특성(및 교육 데이터)으로 인해 개인화된 경우가 많다. 예를 들어 개인(Zang 등, 2014) 또는 검색 활동(Chang 등, 2016)의 리뷰는 설명에 사용되는 설명자 데이터와 ML 모델의 교육 데이터로 사용된다.
요약하자면 개념적 수준에 대한 개인화된 설명의 체계적인 처리는 없다. 또한 기존 방법은 기존 설명 방법의 전체 설계 공간을 포함하지 않는다. 예를 들어 명시적 정보 수집을 사용하는 자동 개인화 기법은 일반적으로 개인과 범주 모두에 대해 개발되지 않았다. 이는 설명자 간에 설명의 해석 가능성이 상당히 다를 수 있다는 인정에도 불구하고(Kirsch, 2017; Ras 등, 2018; Tomsett 등, 2018).

5 설명자 데이터 및 정보
우리는 설명자에 대해 수집할 수 있는 데이터와 정보를 어떻게 얻을 수 있는지 설명한다.

5.1 설명자 정보의 종류

ML에서 개인화 및 설명에 대한 작업을 종합한 결과, i) 사전 지식 - 설명자가 알고 있는 것, ii) 의사결정 정보 - 설명자가 의사결정에 사용하는 정보, ii) 선호 사항 - 설명자가 좋아하고 선호하는 것, iv) 목적 - 설명이 사용되는 목적 등 네 가지 범주의 설명 데이터가 도출되었다. 사전 지식은 ML 지식 및 작업 영역 지식으로 분할된다. 기계 학습 지식은 설명해야 할 ML 방법에 관한 설명자의 전문 지식을 말한다. ML 엔지니어 또는 최종 사용자와 같은 설명자 역할에 따라 특정 수준의 지식을 나타낼 수 있다(Ras et al., 2018). 예를 들어 (Ras et al., 2018): i) 상세한 수학 이론과 DNN의 원리에 대한 지식, ii) DNN 모델을 훈련하고 최종 적용에 통합하기 위한 지식, ii) DNNN 지식, 즉 이론과 구현이 없다. 업무 영역 지식(Task Domain Knowledge)은 질병 인식 시스템을 사용하는 의사나 환자 등 당면한 직무에 대한 사용자의 도메인 지식을 말한다(Doshi Velez and Kim, 2017). 사용자의 전문 지식의 특성은 설명에서 기대하는 정교함의 수준에 영향을 미친다. 예를 들어, 도메인 전문가들은 더 작고 불투명한 모델보다 다소 크고 정교한 모델을 선호할 수 있다(Lavrach, 1999). 의사결정 정보는 설명자가 ML 작업을 수행할 때 사용하는 정보를 의미한다. 이 정보는 도메인 지식에 뿌리를 두고 있을 수 있지만 ML 또는 일반 지식 또는 경험에서 비롯될 수도 있다. 그것은 설명의 해석가능성(Miller, 2018년)에 대한 가장 중요한 기준 중 하나로, 즉 이전의 신념과의 일관성이다. 예를 들어 이미지 인식 태스크 결정 정보는 사용자가 해당 이미지를 분류하는 데 사용할 수 있는 부분이 될 수 있다. 의사결정 정보는 훈련 데이터 및 기능 수준과 같은 다양한 수준에서 수집될 수 있다. 어떤 자료 샘플이 그의 설명을 가장 정당화시키는지 설명자에게 물어볼 수도 있다. 예를 들어, 두 명의 의사가 훈련 중에 동일한 환자 정보에 노출되었을 수 있지만, 그들은 환자 사례에 서로 다른 관련성을 부여할 수 있다. 의사결정을 위해 개인(그리고 그 중요성)에 의한 데이터에서 특징을 추출하는 것도 의사결정 정보를 구성한다. 예를 들어, 사람은 이미지 인식에서 모양보다 물체의 색을 더 중요하게 여길 수 있다. 결정 정보는 설명을 하기 전이나 후에 수집될 수 있다. 예를 들어 계산된 프레젠테이션에 대한 피드백이나 답변은 설명을 개선하기 위해 반복적으로 사용될 수 있다(Fails and Olsen Jr, 2003). 설명이 사용자의 이전 신념을 더 잘 나타내므로 모델에 대한 충실도가 떨어질 수 있다. 즉, 충실도가 떨어질 수 있다. 그러나 개인에 의해 추가로 필터링되는 여러 가지 가능한 설명(Miller, 2018)이 있을 수 있으며 유사한 충실도로 이어질 수 있다.
선호도는 객관적 해석가능성과 같은 설명 품질의 객관적 측정에 반드시 관련되지 않는 설명자의 옵션의 주관적 우선순위를 말한다. 그러나 그것들은 설명에 대한 한 사람의 느낌이나 그녀의 수락(신뢰성)에 강한 영향을 줄 수 있다. 예를 들어, 모델의 desiderata에 관한 사용자의 중요도 등급이나 제약 조건(예: 사용자가 유지하기를 원하는 사생활 수준), 원하는 수준의 설명, 설명, 프레젠테이션 양식 및 Emplo를 이해하기 위해 사용자가 투자하고자 하는 시간 또는 노력 등의 정보를 선호한다.예드 추론(예: 프로토타입을 기반으로 설명하거나 일반 규칙을 사용)
목적은 설명의 의도된 사용을 말한다. 설명에 대한 사전 작업은 기능적 역할(Ras et al., 2018; Tomsett et al., 2018), 최종 사용자, 개발자 또는 데이터 주체를 기반으로 목적을 도출했다. 립톤(2017년)은 ML 해석가능성이 요구되는 이유, 즉 신뢰, 인과관계, 이전가능성, 정보성, 공정하고 윤리적인 의사결정을 열거하고 있다. 그 목적은 또한 설명적인 질문, 즉 무엇을, 어떻게, 그리고 왜에 대한 답을 얻는 것으로 볼 수 있다(Miller, 2018). (아다디와 베라다, 2018년)에 제시된 설명 가능한 인공지능이 정당화, 통제, 개선, 발견을 한다. 개인화에 관해서는 추론과 논쟁을 통해 누군가의 신념을 바꾸는 것을 목표로 하는 설득의 목표를 덧붙인다. 설득은 추천자 시스템에서 일반적인 주제다(Cremonesi et al., 2012).
"시스템에 대한 사전 경험"과 같은 개인화 관련 문헌에서 확인할 수 있는 추가 정보도 활용될 수 있다.


5.2 설명자 데이터 및 정보 획득

선호도는 전통적인 수단에서 컴퓨터 보조 방법에 이르는 다양한 기법을 사용하여 설명할 수 있다(Chen and Pu, 2004). 의사결정 정보뿐만 아니라 ML 및 작업 영역 지식의 추출은 지식 추출 방법을 사용하여 수행할 수 있다(Hoffman 등, 1995; Liou, 1992). 필요한 정보가 암묵적인지 명시적인지에 따라 기법이 크게 다르다. 사람은 자신이 의사결정 과정에서 무엇을 활용하는지 확인하는 등 암묵적인 지식을 표현하기가 어려울 수 있다. 그러나 어떤 주제에 대해 자신이 전문가인지 아닌지를 판단하거나(명확한 지식) 설명의 목적을 진술하는 것은 비교적 쉬운 일일 수도 있다. (Dieste 및 Juristo, 2011)에서 경험적으로 분석한 Elicitation 기법은 (Hoffman et al., 1995)에 근거하여 다음과 같이 세 가지 범주로 분류된다.

익숙한 작업 분석 - 프로토콜 분석, 관찰되지 않는 작업 또는 시뮬레이션 작업과 같은 일상적인 조건에서 작업을 수행할 때 설명자가 수행하는 작업 조사 
 인터뷰 – 비구조적 또는 구조화된 인터뷰를 사용하여 직접 설명자에게 질문 
 숙련된 기술 – 스케일링, 정렬 또는 계층 구조와 같은 수정된 작업을 수행할 때 설명자가 수행하는 작업 조사 대표적인 기법은 레퍼토리 격자(McGeorge and Rugg, 1992년)이다. 분류와 같은 ML 문제에 적용할 수 있다. 목표는 먼저 도메인의 관련 측면을 나타내는 요소 그룹을 선택하여 사람들이 요소를 분류하는 방법에 대한 정보를 설명하는 것이다. 중요한 구조는 세 가지 요소를 제시하고 두 가지가 어떻게 비슷하고 따라서 세 번째 요소와 어떻게 다른지를 질문함으로써 식별된다. 

인터뷰는 명확한 지식을 이끌어내는 데 적합하다. 설명자에 대한 암묵적인 지식은 ML 기법으로 수행할 수 있다(Webb et al., 2001). 이 경우, 익숙한 작업과 고안된 기법을 분석하여 표 2와 같이 이러한 ML 기법을 분류할 수 있다.

		익숙한 작업 분석 : 사용 로그(예: 웹 및 Tian, 2015), 브라우저(Chang et al., 2016)는 마우스 커서 추적(Schneider et al., 2017) 또는 실행된 명령(Damevski et al., 2017) 프로토콜 분석(예: 이미지의 중요한 부분(Das et al., 2017)
		
		협착 기술 : 정렬(예: 문서 관련 지정(Maddalena et al., 2016), 주석을 다는 비디오(Prest et al., 2012) 또는 ML 탐색(Ross et al., 2017), 개념 영상 선택(Kim et al., 2018)

호프만 외 연구진(1995)은 전문가들로부터 도출된 지식을 강하게 강조했다. 관련 작업에 대해 다른 (중복) 분류가 도출되었다. 예를 들어 사용자 프로필(Montaner et al., 2003)을 학습하려면 권장 사항 시스템의 맥락에서 세 가지 범주를 구분하십시오. 즉, 설명자는 필요한 정보, ii) 고정관념을 명시적으로 기술하고, 그룹 구성원 자격을 기반으로 하는 설명자 데이터 수집 및 iii) 교육 세트 - 설명자의 관련 작업 로그 수집 ML 모델이 설명했다.

설명자 데이터를 수집, 처리 및 저장하는 것은 사생활 문제를 야기한다. 데이터 보호 규정(예: 유럽 의회의 GDPR)을 준수해야 한다. 설명자의 인식 개인화 및 프라이버시 트레이드오프의 다양성을 인정하고 처리하는 것이 중요하다(Xu et al., 2011, Awad and Krishnan, 2006; Toch et al., 2012). 예를 들어 아와드·크리슈난(2006)의 조사에서는 개인정보 가치 정보 투명성을 가장 제공하려는 소비자가 가장 많이 제공하는 역설을 보여준다. Toch 외 연구진(2012년)은 사용자의 프라이버시 통제 정도에 관한 이러한 절충을 묘사하는 프레임워크를 제안했다.

6 맞춤형 설명 방법
개인화된 설명은 2단계 프로세스 즉, i) 설명 속성 사용자 정의 및 ii)를 사용하여 작성하여 개인화된 설명을 생성할 수 있다.

6.1 설명 속성 사용자 정의
설명자 데이터를 사용하는 설명 속성을 조정하고 표 3에 나타낸 설명 방법을 고려함으로써 개인화된 설명을 얻는다. 먼저 설명자 데이터가 각 설명 자산에 어떤 영향을 미치는지 논의한다. 그리고 나서, 우리는 설명 방법에 어떻게 적응해야 하는지에 대해 자세히 설명한다.
설명의 복잡성을 개인화하는 데 관련된 설명자 데이터는 ML 지식, 작업 영역 지식, 인지 능력 및 설명에 기꺼이 소비하는 노력이다. 좀 더 복잡한 설명은 기꺼이 설명에 더 많은 시간을 할애할 수 있는 더 박식한 설명자에게 적합할 수 있다. 의사결정 정보의 우선순위는 설명자의 업무 영역 지식에 따라 수행할 수 있다. 예를 들어 질병 인식 과제를 사용하면 의사들은 설명에 사용되는 용어가 다른 환자보다 더 많은 의학 용어를 이해할 수 있지만, 두 명의 의사도 다른 증상을 사용하여 진단을 내릴 수 있다. 보다 시각적인 예는 그림 1의 염도 지도에 의해 제시된다. 귀속 기법은 결정에 가장 강하게 기여하는 특정 영역, 즉 새의 몸을 강조할 수 있다. 머리에 초점을 맞춘 사용자들을 위한 개인화된 방법은 그림 1과 같이 눈이나 부리와 같은 그것의 머리 상세 특성을 더 강조할 수 있다. 두 설명 사이의 가시적인 차이는 ML 모델과 설명자의 입력 및 출력 동작이 정렬되어 있는지(충실성) 의문을 제기한다. ML 모델이 설명자 데이터, 즉 주로 새 머리에 의존하는 특징의 우선순위를 사용하여 동일한 결정을 내리지 못할 경우, 개인화된 설명은 충실도가 부족하기 때문에 부적절할 수 있다.

헤드에 초점을 맞춘 개인 설정을 포함한 설명을 위한 샐러리리티 맵(오른쪽, 자체 그림)

ML 지식 및 목적에 대한 설명자 데이터는 설명의 표시를 개인화하는 것과 관련이 있다. 예를 들어, 의사결정에 관련된 부분을 강조하는 이미지 염률 맵을 사용하면 비전문가에게 모델의 책임을 납득시키기에 충분할 수 있다. 그러나 모델을 개선하고자 하는 ML 전문가에게는 기능 시각화를 추가하는 것이 유용할 수 있다.
