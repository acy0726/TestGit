피드포워드 - 유사성을 파악해 추론하는 개념

자연어 추론 모델은 2개의 인터페이스를 분리 하는데 학습과 추론 근데 이논문은 추론만 구현

CNNs for NLP in the Browser: Client-Side Deployment
and Visualization Opportunities


우리는 브라우저에서 피드 포워드 추론을 완벽하게 수행하는 CNN 네트워크의 JavaScript 구현을 시연합니다. 이러한 배치는 모델이 백엔드 서버 요청을하지 않고도 광범위한 장치에서 클라이언트에서 완벽하게 실행될 수 있음을 의미합니다. 이 디자인은 엄격한 대기 시간 요구 사항 또는 낮은 연결성을 가진 어플리케이션에 유용합니다. 우리의 평가는 자바 스크립트가 배포 대상이 될 가능성을 보여줍니다. 또한 브라우저 내 구현은 정보 시각화를위한 JavaScript 생태계와의 완벽한 통합을 가능하게하여 시각적으로 신경망을 검사하고 내부 동작을 더 잘 이해할 수있는 기회를 제공합니다.

1. 소개
일단 교육을 받으면 신경망 (NN)을 사용하는 피드 포워드 추론은 간단합니다. 일련의 행렬 곱셈, 비선형 성 적용 및 기타 간단한 연산. ONNX와 같은 모델 상호 교환 형식의 등장으로 모델 추리와 모델 교육을 분리하는 깔끔한 추상화가되었습니다. 이러한 맥락에서 우리는 JavaScript를 NLP 응용 프로그램을위한 신경망의 배포 대상으로 검토합니다.
분명히하기 위해, 우리는 훈련에 관심이 없으며 단순히 추론을 위해 배포 할 사전 훈련 된 모델의 존재를 가정합니다.
왜 자바 스크립트인가? 우리는 두 가지 중요한 이유를 제시합니다. 첫째, JavaScript는 모든 웹 브라우저에 상주하므로 전 세계에서 가장 널리 배포되는 플랫폼입니다. 자바 스크립트의 구현은 랩톱에서 태블릿, 휴대 전화, 잠재적으로 "스마트 홈"가젯까지 브라우저가있는 모든 장치에서 클라이언트 측 실행을 위해 모든 웹 페이지에 NN을 임베드 할 수 있음을 의미합니다. 클라이언트에서 추론을 수행하면 서버 요청 및 관련 대기 시간이 필요하지 않습니다. 이러한 배치에서 응답 성 (예를 들어, 선행 예측, 문법 수정)에 대한 높은 요구 또는 낮은 연결성 (예를 들어, 원격 위치 또는 개발 도상국)으로 고통받는 NLP 애플리케이션은 NN 모델을 이용할 수있다. 이러한 배포는 사용자 데이터가 클라이언트를 떠나지 않기 때문에 사용자 개인 정보를 보호합니다. 둘째, 브라우저가 정보 시각화를위한 지배적 인 플랫폼으로 부상했으며 JavaScript 기반 구현은 최신 기술 및 기존 툴킷 (예 : D3.js)과의 완벽한 통합을 지원합니다.
이는 시각적으로 신경망을 검사 할 수있는 기회를 제공합니다. 우리는 문장 분류를위한 CNN 신경 네트워크의 프로토 타입 구현을 시연합니다. JavaScript (Kim, 2014)의 모델 인 감정 분석은 웹 브라우저에서 완전히 실행됩니다. 당연히 추론 성능은 본질적으로 실행되는 코드에 비해 상당히 느려지지만 브라우저는 그럼에도 불구하고 다양한 플랫폼에서 GPU 및 하드웨어 가속을 이용할 수 있습니다. 우리의 구현은 모델이 추출하는 의미 적 n-gram(통계기반 자연어 처리 모델) 기능에 대한 통찰력을 얻을 수있는 간단한 시각화를 가능하게합니다. 이것은 모델을 이해하는 것이 그것을 개선하는 데 중요하기 때문에 교육학 (신경 네트워크에 대한 학생들을 가르치는 것)과 연구에 유용합니다. 전반적으로, 우리의 시각화는 해석 가능한 기계 학습에 대한 새로운 연구 과제에 기여합니다 (Lipton, 2016).

2 배경 및 관련 연구
브라우저 기반 신경망은 결코 새로운 것이 아닙니다. 아마도 그들의 가능성을 가장 잘 보여주는 사례가 Smilkov et al. (2016a)는 유익한 시각화를 사용하여 단순 다중 레이어 퍼셉트론에 대한 역 전파를 설명합니다. 그러나이 작품은 장난감 문제에 초점을 맞추고 주로 교육학에 유용하다는 특징이 있습니다.
최근에 Google Brain은 NN 빌딩 블록을 JavaScript로 가져 오는 오픈 소스 라이브러리 인 TensorFlow.js (이전 deeplearn.js)를 소개했습니다. 구현시이 라이브러리를 활용합니다.
우리의 작업은 단어 삽입과 관련하여 현재까지 해결되지 않은 기술적 과제를 극복합니다. NLP 애플리케이션을위한 대부분의 NN은 입력 문장을 네트워크에 대한 실제 입력으로 사용되는 삽입 행렬로 변환하는 것으로 시작합니다. 퍼가기는 꽤 크고 기가 바이트 일 수 있기 때문에 웹 페이지에 직접 저장하는 것은 비현실적입니다. Lin (2015)에 이어 우리는 효율적으로 액세스 할 수 있도록 단어 벡터를 로컬로 저장할 수있는 IndexedDB(웹브라우저 영구적 저장되는 DB)라는 HTML 표준을 사용하여이 문제를 극복했습니다 (자세한 내용은 아래 참조).


3 기술적 인 구현
Kim (2014)의 CNN 신경망은 다수의 특징지도가있는 단일 문장 입력 임베딩 행렬에 대한 컨볼 루션 (convolutions)과 드롭 아웃 (dropout) 및 소프트 맥스 출력 (softmax output)이있는 완전히 연결된 레이어가 뒤 따르는 풀링으로 구성되는 문장 분류 모델입니다. 직설적 인 아키텍처를 가지고 있기 때문에이 독자는 Kim의 원본 종이를 참조하십시오. 이 작업의 출발점은 모델을 PyTorch로 다시 구현 한 것으로 원래보고 된 결과와 비교할 수있는 정확도를 제공합니다 .
우리의 시연은 추론 성능에 중점을두기 때문에 Stanford Sentiment Treebank에 기반한 정서 분석을 위해 미리 훈련 된 모델을 사용했습니다. 우리는 수동으로 PyTorch에서 모든 가중치를 내보내고 시작시 TensorFlow.js에서 모델 아키텍처를 직접 코딩하여이 가중치를 가져 왔습니다.
Kim CNN은 비교적 단순한 아키텍처를 가지고 있기 때문에 TensorFlow.js는 PyTorch의 것과 매우 유사한 기본 요소를 제공하므로이 구현은 간단합니다. 우리의 구현은 순수한 JavaScript이기 때문에 전체 모델을 웹 페이지의 소스에 직접 포함시킬 수 있으며, 예를 들어 입력을 위해 텍스트 입력 상자에 연결하고 출력을 위해 DOM 조작 코드에 연결할 수 있습니다. 그러나 NLP 애플리케이션을위한 거의 모든 신경 회로망은 입력 표현 (삽입 행렬)을 추론의 첫 번째 단계로 구축하기 위해 사전 훈련 된 단어 벡터를 사용합니다. 비 장난감 어휘의 경우 이러한 단어 벡터는 많은 기가 바이트를 소비합니다. 모든 JavaScript 코드와 관련 리소스가 메모리에로드되므로 메모리 제한 때문에 웹 페이지 또는 외부 리소스에 이러한 데이터를 직접 포함시키는 것은 비실용적입니다. 이것이 가능하다해도 사용자가 브라우저 탭을 새로 고침 할 때마다 모든 데이터를 다시로드해야하므로 대기 시간이 길어지고 사용자 경험이 어색합니다.
이러한 문제를 해결하기 위해 임의의 양의 데이터를 클라이언트 측 저장소에 저장하기위한 저수준 API 인 IndexedDB를 활용합니다. IndexedDB는 HTML5 표준이기 때문에 추가 플러그인 (표준 준수 브라우저라고 가정)이 필요하지 않습니다. IndexedDB에는 풍부한 API가 있지만, 우리의 응용 프로그램에서는 키를 단어이고 값이 해당 단어 벡터 인 간단한 키 - 값 저장소로 사용합니다. 실험을 위해 사용하는 Google 크롬 브라우저에서 IndexedDB는 Bigtable 태블릿 스택과 동일한 기본 설계로 제작 된 디스크 기반 키 - 값 저장소 인 LevelDB에서 지원됩니다 (Chang 외., 2006). 즉, 모든 Chrome 브라우저에는 자바 스크립트를 통해 직접 액세스 할 수있는 최신 데이터 관리 플랫폼이 있습니다.
IndexedDB에서는 추론을위한 모델을 사용하기 전에 사용자가 먼저 단어 embedding을 다운로드하여 로컬에 저장해야합니다. 편의상, 모델 가중치는 동일한 방식으로 처리됩니다. 이 작업은 한 번만 수행하면되며 저장소가 명시 적으로 회수 될 때까지 모든 데이터가 클라이언트에 보관됩니다. 즉, 한 번 설정 한 후에는 모델 연결이 외부 연결이 필요없이 브라우저에서 로컬로 발생합니다. 따라서 예측할 수없는 서버 대기 시간에 의존하지 않는 긴밀한 상호 작용 루프가 가능합니다.


4 성능 평가
가장 먼저 다루어야 할 사항은 자바 스크립트 구현의 성능입니다. 모델 추론이 원래 수행 한 것보다 얼마나 느린가? 우리는 MacOS 10.13을 실행하는 Intel Core i5-5257U 프로세서 (2 코어)가 장착 된 2015 MacBook Pro 랩톱에서 브라우저 내 유추를 평가했습니다. Intel Core i7-6800K 프로세서 (6 코어) 및 NVIDIA GeForce GTX 1080 GPU (Ubuntu 16.04 실행)가있는 모델을 교육하는 데 사용 된 데스크탑 컴퓨터와 성능을 비교했습니다.
우리 모델은 CUDA 8.0을 실행하는 PyTorch v0.3.0을 사용하여 구현되었습니다. 모든 실험은 Stanford Sentiment Treebank 검증 세트에서 수행되었습니다. 브라우저에서 JavaScript 실행의 비동기 특성으로 인해 TensorFlow.js API는 한 번에 입력 문장의 일괄 처리에 유추를 적용합니다. 따라서 1, 32, 64 및 128 문장의 배치에 대해 배치 당 대기 시간을 측정했습니다.
평가 결과는 표 1에 나와 있습니다. 표의 첫 번째 블록은 데스크톱에서 실행중인 PyTorch의 성능과 GPU 가속 기능의 사용 여부를 보여줍니다. 예상대로, GPU는 배치 추론을 위해 병렬 처리를 이용할 수 있지만 개별 문장에서는 CPU가 약간 느립니다. 표의 아래쪽 블록에는 자바 스크립트 구현을 Google 크롬에서 실행 한 결과 (v64)가 나와 있습니다. 우리는 데스크톱과 랩탑을 GPU 가속화 여부와 비교했습니다. 가장 일반적인 경우 (단 하나의 문장에 대한 추론)의 경우 브라우저는 GPU에서 느린 속도입니다. GPU가 없으면 성능이 ~25 배 정도 떨어집니다.
위의 수치는 추론 시간만을 포함합니다. MacBook Pro에서 각각 1, 32, 64 및 128 배치 크기의 워드 벡터로드는 7.4, 214, 459 및 1184 ms입니다. 앞에서 설명한 것처럼 IndexedDB를 사용하려면 단어 벡터 및 모델 가중치를 한 번 다운로드해야합니다. 이 단계는 MacBook Pro에서 16,271 단어 벡터에 대해 약 16 초 걸립니다 (간단히하기 위해 실험에 필요한 어휘 만 다운로드합니다). 모델 자체로드에는 약 1 초가 걸립니다.
우리의 구현은 JavaScript로되어 있기 때문에 우리 모델은 웹 브라우저가있는 모든 장치에서 실행됩니다. 이를 입증하기 위해 Apple A10X Fusion 칩이 장착 된 iPad Pro, Qualcomm Snapdragon 810 Octa-core CPU가 장착 된 Nexus 6P 및 Apple A8이 장착 된 iPhone 6과 같이 편리한 액세스가 가능한 여러 장치에서 성능을 평가했습니다. 칩. 이러한 결과는 표 1에도 나와 있습니다. 예상 한대로이 장치의 성능은 랩톱보다 낮지 만 흥미롭게도 이러한 장치의 배치 추론은 GPU 가속 기능이없는 브라우저의 배치 추론보다 빠릅니다. 이는 하드웨어 가속이 오늘날 많은 장치에서 표준 기능임을 나타냅니다. 이 실험은 JavaScript의 편재성을 활용하여 다양한 장치에 신경망을 배포 할 수있는 가능성을 보여줍니다.

PyTorch
Desktop GPU (Ubuntu 16.04) 2.9 3.0 3.1 3.1
Desktop CPU (Ubuntu 16.04) 4.3 43 86 130
Chrome Browser
Desktop GPU (Ubuntu 16.04) 30 56 100 135
Desktop CPU (Ubuntu 16.04) 783 47900 110000 253000
MacBook Pro GPU (MacOS 10.13) 33 180 315 702
MacBook Pro CPU (MacOS 10.13) 779 56300 126000 297000
iPad Pro (iOS 11) 170 472 786 1283
Nexus 6P (Android 8.1.0) 103 541 1117 1722
iPhone 6 (iOS 11) 400 1336 3055 7324
표 1 : N 개의 문장 일괄 처리를 위해 Chrome에서 실행중인 CNN의 기기 별 대기 시간


5 피쳐 맵의 시각화
브라우저 내 자바 스크립트 구현의 또 다른 주요 이점은이 섹션에서 설명하는 최신 브라우저 기반 정보 시각화 기술 및 툴킷 (예 : D3.js)과의 완벽한 통합입니다. 시각화는 두 가지 목적에 유용합니다. 첫째, 학생들은 신경 네트워크가 어떻게 작동하는지 학생들에게 가르쳐주는 직관적 인 도움이됩니다. 깊은 학습을위한 많은 교육 자료가 있지만, 학생들이 조작 할 수있는 웹 페이지에 직접 삽입 된 대화 형 신경망의 편리함을 능가하는 것은 없습니다. 둘째, "해석 가능한"기계 학습 (Lipton, 2016)에 대한 관심 증가에 기여하는 시각화는 다양한 네트워크 구성 요소가 최종 예측을 산출하는 데 어떻게 기여 하는지를 이해하는 데 도움이됩니다. 신경 네트워크 시각화의 많은 예가 있지만 (Smilkov 등, 2016a, Bau 등, 2017, Olah 등, 2018), 대부분 입력 및 기능 맵이 시각적으로 해석하기가 훨씬 쉬운 비전 애플리케이션에 중점을 둡니다 . NLP 응용 프로그램의 근본적인 문제는 고유 한 시각적 의미가없는 추상적 의미 공간에 단어 포함 (및 확장, 기능 맵)이 존재한다는 것입니다. 임베딩을 가장 잘 시각화하는 방법은 아직 열려 있습니다 (Smilkov et al., 2016b; Rong and Adar, 2016).
그럼에도 불구하고 CNN의 기능 맵은 n-gram 기능 감지기로 생각할 수 있습니다. 우리의 정서 분석 응용 프로그램 (그리고 더 일반적으로 문장 분류)을 위해, 우리는 두 가지 관련 질문에 대답하기위한 시각화를 설계했습니다. 첫째, 문장이 주어 졌을 때, 어떤 특징지도가 많이 활성화되었고 어디에서? 둘째, 특정 피쳐 맵이 주어지면 어떤 토큰 시퀀스가 ​​문장의 코퍼스에서 활성화됩니까?


그림 1의 시각화는 첫 번째 질문에 대답하도록 설계되었습니다. 왼쪽 가장자리를 따라 가며 우리가 조사하고있는 문장입니다. 이 섹션의 예제는 Stanford Sentiment Treebank의 개발 세트에서 가져온 것입니다. 각 열은 특정 너비의 지형지도를 나타냅니다. 각 셀은 지형지 물 맵이 적용되는 문장의 해당 n 그램의 첫 번째 토큰과 정렬됩니다. 히트 맵 (즉, 청색 채도)은 문장 내의 그 특정 n-gram상의 모든 특징 맵에 걸친 최대 활성화에 대응한다. 인터랙티브 한 시각화에서 우리가 셀 위에 마우스를 가져 가면 포커스가 확대되고 약간 오프셋되어 문장에 해당하는 n 그램이 굵은 글씨로 강조 표시됩니다. 이 문장에서 우리는 너비 3의 필터가 n-gram 시퀀스 [예외적 인 성능]에 의해 가장 많이 활성화되었음을 알 수 있습니다. 기능지도의 활성화를 요약하기 위해 색상을 사용하는 방법은 여러 가지가 있지만 Google에서 가장 통찰력있는 것으로 나타났습니다. 이 시각화를 통해 너비가 4와 5 인 지형지도가 문장의 다른 부분에서 활성화된다는 것을 알 수 있습니다. 그림 1의 시각화에서 일부 기능 맵은 n-gram의 탁월한 성능에서 크게 활성화됩니다. 하지만 어느 것이지? 이 질문에 대답하기 위해 그림 2의 시각화로 피벗 할 수 있습니다. 여기에서 대답은 필터 12임을 알 수 있습니다.
개발 세트의 문장에서 가장 높은 활성화를 트리거합니다. n-gram은 쉬운 브라우징을 위해 컨텍스트 기반 키워드 형식으로 정렬됩니다. 각 문장의 왼쪽에 x / y를 표시합니다. 여기서 x는 지상 진실 레이블이고 y는 예상 레이블입니다. 여기서는 모든 n 그램이 퍼포먼스의 긍정적 측면과 관련이 있음을 분명히 알 수 있습니다.이 기능 맵을 통해 포착 된 의미에 대한 통찰력을 얻을 수 있습니다. 이 시각화에서 어떤 문장을 클릭하여 그림 1의 문장 중심 시각화로 되돌릴 수 있습니다.


6 향후 연구 및 결론
우리는 브라우저에서 완전히 실행되는 CNN 신경 네트워크의 JavaScript 구현을 설명합니다. 당연히 브라우저 내 추측은 상당히 느립니다. 그러나 많은 애플리케이션에서 JavaScript 구현의 장점 (웹 페이지에 신경망을 포함 할 수있는 기능, 다양한 장치에서 인터넷 연결없이 실행할 수있는 기능 및 기회)을 고려할 때 이러한 성능 저하는 가치가있을 수 있습니다 모델을 해석하는 데 도움이되는 시각화 기능을 제공합니다.
지속적인 작업은 모델 교육 및 브라우저 배포를보다 잘 통합하는 데 중점을 둡니다. 현재 PyTorch 모델을 JavaScript로 이식하려면 손으로 TensorFlow.js로 지루하게 모델을 다시 작성해야합니다. 라이브러리가 TensorFlow 모델을 읽는 것을 지원하지만 PyTorch의 수입업자는 아직까지 존재하지 않습니다. 적합한 어댑터가 구축 된 경우 ONNX 모델 상호 교환 형식은 원활한 통합을 지원하는 인터 링구아를 제공 할 수 있으므로 JavaScript의 신경망을 실행하는 것이 일상화 될 수 있습니다.
