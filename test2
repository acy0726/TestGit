model induction

Bayesian Teaching을 기반으로 한 모델 결정을 설명할 수 있는 최적의 교육 사례 선택

• 다음에 대한 예제 기반 설명:
• 전체 모델
• 사용자가 선택한 하부 구조
• 사용자가 제출한 예제


베이지안 확률
빈도론과 베이지안이 확률을 바라보는 관점이 어떻게 다를까요? 가령, '주사위를 던져서 3이 나오는 확률이 1/6이다.'라는 명제에 대하여, 빈도론자는 이렇게 해석할 것입니다.
"1000번을 던지면 166번, 10000번을 던지면 1666번 3이 등장한다."

하지만 같은 확률이라도 베이지안은 다르게 해석합니다.
"주사위를 던질 때, 3이 나온다고 1/6(16.66%) 확신할 수 있다."

즉, 빈도론자는 확률에 대해 '사건이 일어나는 장기적인 확률'로써 오로지 경험적 사실만을 통해 이야기할 수 있다는, 객관적인 입장이고 베이지안은 '지식이나 판단의 정도를 나타내는 수단'으로써, 주관적인 입장을 취합니다. 





베이시안 강의의 목표는 데이터 교육 세트를 제시함으로써 학습자에게 목표 모델을 유도하는 것이다. 이것은 두 종류의 추론을 추적할 것을 요구한다. 즉, 교사 추론과 가능한 목표 모델의 공간에 행해지는 학습자의 추론이 그것이다.


Explainable Artificial Intelligence via Bayesian Teaching
현대 기계 학습 방법은 점점 강력해지고 불투명해지고 있다. 이러한 불투명성은 알고리즘이 폐기할 수 있는 중요한 결정을 내리고 있는 다양한 도메인에 걸쳐 우려되는 사항이다. 그러므로 기계 학습 시스템의 설명은 흥미를 증가시키는 것이다. 우리는 Bayesian 교수법에 대한 최근 연구를 기반으로 한 설명-별표 접근방식을 제안한다. 이 접근방식은 전체 데이터 세트와 유사한 결론을 도출할 수 있는 데이터의 작은 부분 집합을 선택하는 것을 목표로 한다. 우리는 이 접근법을 논의하면서 몇 가지 주요 이점을 설명한다. 첫째, 감독, 감독되지 않은 학습 및 보강 학습(심층 학습 포함)을 포함한 모든 모델을 강건한 해석으로 포괄할 수 있는 능력. 둘째, 우리는 이 접근방식의 경험적 토대를 다른 요원들로부터 배우는 인지과학에서 논한다. 셋째, 이 접근방식의 약속을 완전히 실현하기 위해 장애물을 개략적으로 설명한다. 우리는 기계 학습과 실제 문제에 대한 적용에 대한 의미를 논의함으로써 결론을 내린다.


최근의 기계 학습의 발전은 중요하고 어려운 학습 문제에서 놀라운 성과를 낳았다. 예를 들어, 알고리즘은 최근 ATARI 게임[1]을 배우고, 자동으로 이미지를 분류하며[2] 심지어 바둑 [3] 게임에서도 챔피언을 이기는 것을 배우는데 놀라운 성공을 보여주었다. 이러한 기계 학습 방법은 알파고[4]의 경우 2만 노드의 순서에 따라 엄청난 수의 잠재 변수를 갖는 모델에 적용되는 영리한 추론 방법에 기초하는 경우가 많다. 이러한 방대한 잠재적 변수 풀에 의해 제공되는 유연성은 이러한 모델들이 가능한 엄청난 데이터 배열을 맞출 수 있게 하지만, 또한 모델 추론을 해석하기 어렵게 만드는 변수들 사이에서 복잡한 상호의존성을 산출한다.


모델의 불투명성은 이해를 달래기 위해 애드혹적인 방법들의 집합을 통해 실제로 다루어진다. 이 방법들은 다양한 범주로 나뉜다. 첫 번째 그룹은 불투명 모델에 적용되는 방법이다. 여기에는 제한된 영역에서 특정 예측을 설명하기 위한 신경망의 층을 시각화하는 많은 기법[5, 6]과 텍스트 또는 캡션의 자동 생성이 포함된다[7, 8, 9]. 두 번째 그룹은 구조화된 상징적 표현[예: 10]을 채택하여 설명할 수 있도록 명확하게 설계된 기계학습 모델로 구성된다. 때로는 확률론적 추론과 결합된다[예: 11]. 세 번째 그룹은 다른 입력에 대응하여 모델의 출력 동작 예측을 최적화함으로써 기계 학습 모델의 동작을 훈련의 대상으로 취급한다[예를 들어 12]. 네 번째 그룹은 기술 전문가에게 그 모델을 설명하는 것이다.

기계학습 모델의 결과를 이해하기 위한 이러한 기존 방법에는 중대한 한계가 있다. 기계 학습 도구 또는 시각화의 임시 적용은 원래 모델에 대한 통찰력을 제공할 수 있다. 그러나, 다른 방법을 언제 적용할지, 또는 이러한 방법이 오도되거나 실패하기를 기대하는 이유는 알려주지 않는다. 는 문자 세대 같은 특정한 활용 사례,,에 맞춰 만들어져 있는 접근 방식은 설명할 수 있는 AI의 계획에 따른 개발 가이드 일반 원칙을 제공하지 못한다. 많은 상징적 모델의 경우, 개별 상징 구성요소를 해석할 수 있는 반면, 이들의 상호작용을 탐색하는 것은 어려울 수 있다. 더욱이 이러한 모델의 추론은 종종 설명가능성에 이용되지 않는 구조와 분포에 대한 분포를 산출한다. 또한 인적 영역 전문가에게 결과를 설명하기 위해 인적 기술 전문가에 의존하는 모든 접근방식은 그러한 기술적 전문지식의 제한된 숫자와 높은 비용 때문에 병목현상에 직면한다. 더욱이, 기술 전문가들이 그들 자신의 모델을 이해하는 정도는 인기 모델의 고장 모드에 대한 최근 시연에 비추어 볼 때 논쟁의 여지가 있다[13, 14].

처음 세 그룹의 접근방식의 공통 테마는 불투명한 기계 학습을 설명하기 위해 해석 가능한 기계 학습을 사용하는 것이다. 이러한 접근방식은 학습과 설명이 어떻게 관련되어 있는지를 이해하는 핵심 문제를 회피한다. 우리는 이 관계 설명의 논리가 모델의 역으로를 위한 가장 관련 데이터를 도메인(수준은 아니지만 기술)전문가들을 제시할 때 나타날 수 있다고 주장한다.모델 훈련. 이 견해는 모든 기계 학습 모델이 데이터에 대해 훈련되고 데이터는 사용자와 모든 모델 사이의 자연스러운 공통 언어라는 두 가지 기본적인 관찰에 의존한다. 사례에 의한 설명만으로는 철학자와 인지과학자가 설명에 의해 무엇을 의미하는지 알 수 없지만[15], 그것은 귀납 추론에 대한 사람들의 성향을 이용하는 강력한 부분집합을 제공한다. 이에 비추어 볼 때, 우리는 모델의 추론을 가르치기 위해 예시 데이터를 샘플링하는 방법인 Bayesian teaching은 광범위한 종류의 기계학습 모델을 설명하는 일반적인 모델 불가지론적인 방법이라고 제안한다.
다음 절에서는 적용 범위(제2절)와 함께 베이시안 교수법을 소개하고(제3절), 방법의 실증적 지원 제시(제4절), 그 효용성을 넓히고 증가시키고 검증하는 과제를 제기하고(제5절), 다른 작품과의 관계를 논의하며(제6절) 일부 결론적인 발언을 할 것이다.




2.
예를 설명으로 사용하는 것은 어디에나 있다. 인간은 몇 가지 예에서 원칙과 이해를 유도할 수 있는 능력을 가지고 있다[16]. 따라서, 마음 속에서의 설명별 방법인 Bayesian teaching은 사용자가 모델을 일반적인 방식으로 이해하도록 도울 수 있으며, 모델의 개별 결정에 근거한 것에서부터 모델이 성공하고 실패하는 조건에 기초한 것에 이르기까지 모든 레벨에 대한 사용자 결정을 암묵적으로 지원할 수 있다. 더욱이, 베이지안 가르침은 인지과학에 뿌리를 두고 있으며, 상호작용 환경에서 인간의 추론을 이해하도록 개발되었다[17, 18]. 선택한 예가 일치함을 보여 주었다.
인간들이 근본적인 생성 과정을 대표한다고 생각하는 것 [19]. 우리는 또한 선택된 예들이 어떻게 인간의 학습을 용이하게 하고 설명하는지 보여주었다 [20, 21]. 이와 같이, 이 프레임워크는 설명 가능한 인공지능에 내재된 인간-기계 상호 작용과 잘 들어맞는다. 설명에는 일반적으로 설명자와 설명자 사이의 전후 통신이 필요하기 때문이다.

Bayesian 교수법에서, 교수 문제는 데이터의 작은 부분 집합을 선택하는 것으로 공식화되며, 높은 확률로 학습자 모델을 올바른 추론까지 이끌어 간다. 프레임워크는 확률론적 모델에 적용될 수 있으며, 학습 모델에 입력되는 교육 데이터가 무엇이든 사용한다. 베이시안 교수법의 공식은 [17, 22]

여기서 x는 교육 데이터의 어떤 부분집합이 될 수 있다. Θ는 대상 모델을 나타낸다. 는 잠재된 특징, 관계, 그래머, 프로그램 또는 이들의 조합과 같은 전체 모델 또는 특정 하부 구조물이 될 수 있다. PT(x|Θ)는 목표 모델 Θ를 설명하기 위한 교육 사례로 x를 선택할 확률이다. PL(Θ|x)은 학습자의 후부 i이다.x를 받은 후의 추론; P(x)는 특정 종류의 예(예: 소형 서브셋 선호)에 대한 편향을 설명하고 있으며, 통합은 훈련 데이터의 모든 파티션(즉, x의 크기가 m이고 전체 훈련 말뭉치의 크기가 N이면 N-choose-m 파티션이 있다.


2.1 설명 가능한 모델 및 문제의 범위 특성

베이시안적 가르침은 베이시안적 추론으로서 주조될 수 있는 어떤 모델에도 적용될 수 있다. 일반적으로 도입되는 방식에 따라 이러한 모델의 범위를 특성화할 수 있다. 이 특성화는 범위를 (1) 데이터와 모델 변수에 대한 확률을 명시적으로 정의하는 모든 생성 모델, (2) 나중에 음의 로그 가능성과 음의 로그로 해석되는 손실 기능이 있는 의사결정 이론적 프레임워크에 처음 도입된 모델, 그리고 다음과 같은 세 가지 유형의 모델로 구분한다. (3) 베이지안(Bayesian)이 되기 위해 확장된 비(非)베이지안 모델 따라서 베이시안 모델의 범위는 포괄적인 [cf. 23]이며, 기계 학습의 모든 영역을 포함한다.

이하에서는 감독, 감독하지 않는 것, 보강하는 것, 심층 학습의 문제 영역을 조사하여, 먼저 x와 Θ가 대응하고 있는 것을 기술한 다음, 앞 항에서 언급한 세 가지 유형의 모델 각각에 대해 주목할 만한 예를 제공한다. 깊은 학습은 실제로 문제 영역이라기 보다는 모형의 한 종류라는 점에 주목하라. 그러나 우리는 그것이 현재 지배적인 접근방식일 뿐 아니라 가장 불투명한 모형의 클래스이기 때문에 그것을 기계학습의 별개의 분야로 다룰 것이다.

감독된 학습의 경우, Eq. 1의 x는 예시 및 라벨이며, Θ는 일반적으로 회귀 함수 또는 분류 경계의 모양을 결정하는 가중치를 말한다. 강력하고 확장되는 감독 생성 모델의 등급은 가우스 프로세스에 기초한 모델이다[24]. 차별적 모델은 보통 손실 기능에 의해 정의된다. 흥미롭게도, 그들 대부분은 인기 있는 지원 벡터 기계를 포함한 베이시안적인 해석을 가지고 있는 것으로 밝혀졌다[25, 26]. 베이시안 적응 회귀 나무[27]와 몬드리안 숲[28]은 알고리즘적으로 기본이 되는 개발로 인해 베이시안 해석의 명확성을 갖지 않는 인기 있는 블랙박스 모델인 난형 숲의 베이지안 버전으로 간주할 수 있다.

감독되지 않은 학습의 경우 x가 그 예이며, Θ는 일반적으로 클러스터링의 숨겨진 혼합물 매개변수, 텍스트 의미론 모델의 주제, 시계열 분석의 상태 및 전환 매트릭스와 같은 잠복 구조다. 무한 가우스 혼합 모델[29] 및 잠복 디리클릿 할당[30]과 같은 디리클릿 프로세스에 기초한 모델은 강력하고 확장된 생성 모델의 클래스를 형성한다. 원리 요소 분석은 도입 후 수년이 지난 후 확률론적 해석이 발견되는 두 번째 유형의 예다[31]. 확률론적 잠재 의미 분석[32] 및 확률론적 행렬 요인[33]은 권장자 시스템에 유용한 인기 비-바이에스 모델의 확률론적 버전의 예다.

보강학습의 경우 x는 행위, 관찰(또는 방문한 상태) 및 대리인이 경험한 보상의 이력에서 취하며, Θ는 학습된 정책이며 학습된 모델이다.
천하의 강화 학습 알고리즘은 모델 기반과 모델 없는 두 가지 맛이 있다. 모델 기반 학습의 측면에서, 최적의 정책을 찾는 문제는 베이시안적 해석을 가지고 있으며, 결정론적 및 부분적으로 관찰 가능한 마르코프 의사결정 프로세스 설정에서 베이시안적 추론 문제로 정확하게 번역될 수 있다[34, 35]. 이 번역은 고려 중인 세계 모델에 대한 생성 모델을 구성함으로써 이루어진다. 모델 없는 측면에서, 정책 개선을 위한 두 가지 인기 있는 비 베이시안 알고리즘(임시 차이와 주-액션-레워드-상태-액션 알고리즘)은 가우스 프로세스를 주 행동 값에 우선시함으로써 베이시안 알고리즘이 되었다[36]. 이것들은 세 번째 유형의 예들이다.

깊은 학습을 위해 x는 다시 훈련의 예시, Θ는 딥 네트워크의 가중치다. 잘 알려진 세 가지 생성 심층 모델은 깊은 믿음의 네트워크[37], 깊은 볼츠만 기계[38] 및 깊은 가우스 과정[39]이다. 두 가지 잘 알려진 차별적 심층 모델은 깊은 경련과 반복적인 신경망이다[40]. 그들은 현재 많은 감독된 학습 과제들을 위한 최고의 기계 학습 알고리즘이다. 최근의 연구는 이러한 깊은 네트워크를 훈련시키는 현대적 방법이 깊은 가우스 프로세스에 대한 가변 근사치를 수행하는 것과 어떻게 관련되어 있는지를 보여주었고, 그들의 베이시안 해석에 대해 빛을 발했다[41]. 그 의미는 완전히 바이에스식의 깊은 가우스식 훈련방식이 이 깊은 네트워크들의 베이에스식 확장이 될 것이라는 것이다. 그러한 훈련은 최근에 큰 돌파구를 발견했고, 처음으로 대규모 회귀 문제에 깊은 가우스 과정을 적용할 수 있게 했다[42].

요약하면, 베이지안 모델의 범위는 광범위하고 포괄적이다.
기계 학습의 모든 영역 게다가, 베이지안 모델은 기계학습뿐만 아니라 신경과학과 인지과학에서도 빠르게 확대되고 있다. 베이시안 강의는 베이지안을 캐스팅할 수 있는 어떤 모델에도 적용이 가능하기 때문에, 설명 가능한 인공지능을 발전시키는데 큰 영향을 미칠 것이다.


3 경험적 지원
바이에스식 교수법은 가르침과 배움의 인지과학에 뿌리를 두고 있다. 인지과학 문헌은 이 접근법을 교육학적 추론의 기치 아래 연구해 왔다. [17] 게임판의 축 정렬 직사각형 개념과 실제 개념의 내부 또는 외부로 라벨이 표시된 예제들이 있는 단순한 규칙 기반 개념 학습 환경에서 교육과 학습을 조사했다[cf. 43]. 그들은 참가자가 가르칠 때 예시를 선택하고, 학습할 때 개념에 대한 추론은 상호 협력을 가정하는 모델로 잘 특징지어졌다는 것을 발견했다[17]. [18] 이 연구를 확장하여 프로토타입 범주(가우스 분포; [cf. 19])와 인과관계 네트워크에 대한 인간의 가르침과 학습을 탐구하였다. [44]는 식견이 있고 도움이 되는 정보원으로부터 배운 후, 그 예가 [또한 45]를 가르치도록 선택되었다고 가정했을 때 예측한 바와 같이, 탐색적 놀이가 줄어든 것을 발견했다. 순진한 정보원으로부터 알게 된 후 관찰되지 않았던 패턴 이 일은 집중되었다.
교사와 학습자 간의 협력을 전제로 하고, 교사와 학습자 사이의 재귀적 추론으로서 공식화된 모델에 대하여.

제2절에 기술된 베이시안 교수법은 [17, 18]에 기술된 교육학적 추론 모델의 한 단계적 근사치다. [19] 범주에 관한 사례의 대표성에 대한 사람들의 판단을 특징짓기 위해 유사한 형식주의를 제안했다. 이 모델은 다차원 유사성 공간에서 가우스 분포로 모델링된 범주를 개별적으로 고려했다. 언어 문헌에도 유사한 접근법이 채택되어 아동에게 입력하는 언어의 문법적 구조에서 수정을 설명하고, 실용성이 스피커와 청취자에게 미치는 영향을 포착했다[47].

모델링의 관점에서, 베이시안 교수법은 모든 후보 하위집단의 한계 가능성을 계산할 것을 요구한다. 이러한 이유로, 위에서 설명한 경험적 연구는 주로 단순한 자극과 개념으로 매우 제한적인 맥락에 포함되었다. 기계학습 모델을 설명할 때 이러한 단순한 상황을 넘어 보다 현실적인 종류의 문제까지 모델을 확장하는 것은 어려운 계산상의 문제다. 우리는 순차적 중요도 샘플링을 통해 한계우도를 근사화하기 위해 MCMC(Markov Chain Monte Carlo) 기법을 활용함으로써 이 문제를 해결하기 시작했다 [21, 22]. 이 접근방식은 일반적이고 확장 가능하며, 감독되지 않은 클러스터링 문제에 대해서는 무한 가우스 혼합 모델(IGMM)에, 주제 모델링에 대해서는 잠재된 디리클릿 할당(LDA)에 적용되었다[22].

[21]에서는, 언어의 음성 범주를 가르치기 위한 최적의 입력 예로서 유아 지도 언어(유아들과 대화하는 기이한 방식)를 조사했다. 이전의 결과는 혼란스러운 결과 패턴을 보여주었다: 모음의 범주에 의해 점유된 공간이 유아 지시 언어에서 증가하는 반면, 일부 모음의 범주는 실제로 더 가까워지고 (공동) 분산이 증가한다. 첫 번째 특징은 외관상으로는 학습모음 범주를 더 쉽게 만들 수 있지만, 다른 것들은 그 가능성과 일관성이 없어 보인다. 우리는 IGMM으로 유아의 음소리의 군집화를 모델링하고, 유아가 성인 음성에서 발견되는 음성 범주를 유추하는 것을 배우는 데 가장 도움이 되는 소리를 선택하기 위해 바예스 교법을 적용했다. 우리는 이 접근법에 의해 선택된 소리가 유아 주도 언어와 일치한다는 것을 보여주었다. 이러한 일관성은 유아 주도 언어가 유아들에게 성인 언어에 대해 가르치는 수단이 될 수 있음을 시사하며, 만리교 교리는 복잡하고 현실적 영역에서 인간의 행동과 일치한다.

[20]에서는 순진한 인간 사용자들에게 데이터의 새로운 통계 패턴에 대해 가르치기 위해 데이터의 정량화, 분석 및 표시를 자동화하는 파이프라인을 개발하였다. 이 파이프라인은 이미지의 말뭉치를 가져와서 IGMM을 사용하여 말뭉치로부터 시각적 범주를 자동으로 추론하고, 추출된 범주를 설명하는 최선의 요약으로서 작은 영상 집합을 출력하기 위해 베이지안 가르침을 적용했다. 예를 들어 가장 가능성이 높은 예를 본 사람들보다 분류 과제(즉, 더 정확하게 추론된 모델의 범주)에서 이러한 교육 사례를 본 나ive 인간 학습자(MTurk)가 더 잘 수행되었다. 이 결과는 베이시안 강의가 순진한 인간 사용자들이 모델의 행동에 대해 더 나은 예측을 할 수 있도록 도울 수 있음을 시사한다.

요약하자면, 베이지안 가르침은 다양한 지각적 영역과 인지적 영역에서 인간이 인간을 가르치는 방식과 일치하는 것으로 나타났다. 자동 요약 도구로 사용될 때, 기계 학습 모델의 그것들과 일치하도록 인간의 판단을 강요하는 것으로 나타났다. 이러한 결과는 베이지안 교육이 기계학습 모델의 지식을 인간에게 전달하는 데 사용될 수 있다는 증거다.

4. 
이전 섹션에서 논의한 바와 같이 베이시안 강의를 보다 일반적이고 확장성 있게 만드는 데는 약간의 진전이 있었지만, 베이지안 강의를 인공지능을 설명하는 일반적이고 유용한 도구로 만드는 데는 많은 과제가 남아 있다. 이 섹션에서는 우리가 본질적인 도전이라고 느끼는 것을 나열한다.








