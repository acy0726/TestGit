TensorFlow.js는 JavaScript로 기계 학습 알고리즘을 작성하고 실행하기위한 라이브러리입니다. TensorFlow.js 모델은 웹 브라우저와 Node.js 환경에서 실행됩니다. 이 라이브러리는 TensorFlow 에코 시스템의 일부로 Python과 호환되는 일련의 API를 제공하므로 모델을 Python과 JavaScript 생태계간에 이식 할 수 있습니다. TensorFlow.js는 광범위한 JavaScript 커뮤니티의 새로운 개발자에게 기계 학습 모델을 구축 및 배포하고 새로운 클래스의 온 디바이스 계산을 가능하게했습니다. 이 백서에서는 TensorFlow.js의 디자인, API 및 구현에 대해 설명하고 일부 유익한 사용 사례를 중점적으로 설명합니다.


기계 학습 (ML)은 소프트웨어 시스템에서 중요한 도구가되어 기존 응용 프로그램을 향상시키고 완전히 새로운 응용 프로그램을 가능하게합니다. 그러나 ML 용으로 제공되는 소프트웨어 플랫폼은 학술 및 산업계의 기술 기반을 반영합니다. 프로덕션 수준의 ML 라이브러리는 대개 Python 및 C ++ 개발자 용으로 작성됩니다. 그럼에도 불구하고 프론트 엔드와 백엔드의 광대 한 커뮤니티가 있습니다.
높은 속도로 계속 성장하고있는 JavaScript (JS) 개발자. Python (GitHub.com, 2017)의 1 백만에 비해 2017 년에 JS에 230 만 개의 GitHub 풀 요청이있었습니다. 2018 년 Stack Overflow Developer Survey에 따르면 JS는 가장 일반적으로 사용되는 프로그래밍 언어입니다 (StackOverflow.com, 2018).
이러한 관심 부족은 중요합니다. JS 환경은 새롭고 차별화 된 응용 프로그램 클래스를 지원할 수 있습니다. 온 디바이스 계산은 데이터 프라이버시, 접근성 및 대기 시간이 짧은 대화식 애플리케이션을 비롯한 많은 이점을 제공합니다. JS 개발자 커뮤니티의 역량 강화는 새로운 종류의 애플리케이션으로 이어질 수 있습니다.
이 백서에서는 JS 커뮤니티의 중요성과 ML을위한 웹 기반 응용 프로그램의 중요성에 대한 동기로 TensorFlow.js 라이브러리의 디자인과 개발에 대해 설명합니다.
TensorFlow (Abadi et al., 2016) 생태계의 일류 시민 인이 플랫폼은 JS에 고성능 ML 및 수치 계산 기능을 제공합니다. ML 용 오픈 소스 JS 플랫폼이 여러 개 등장했지만 TensorFlow.js는 브라우저에서 GPU에 대한 통합 된 교육 및 추론을 지원하는 최초의 제품으로 서버 측 배포를위한 완전한 Node.js 통합을 제공합니다. 우리는 TensorFlow.js가 높은 수준의 라이브러리, 포괄적 인 테스트 및 명확한 확장 성을 포함하여 높은 수준의 생산 체제를 갖추도록 노력했습니다. JS 커뮤니티는 이미 상당한 이해를 보았습니다.
우리는 TensorFlow.js를 구축 한 경험의 세 가지 주요 측면에 대해 논의합니다. 첫째, 우리는 JS 환경의 고유 한 문제점과 이점을 설명합니다. 둘째, 표준 웹 개발 실무와 TensorFlow와의 호환성과 JS 환경의 한계를 극복하기 위해 사용한 기술 간의 균형을 나타내는 라이브러리의 디자인 세부 사항, API를 다룹니다. 마지막으로, TensorFlow.js에서 사용할 수있는 몇 가지 흥미 있고 새로운 사용 사례에 대해 설명합니다.

2 배경 및 관련 연구
TensorFlow.js의 디자인은 JS 환경의 특정 제약에 근거합니다. 여기에서는 JS가있는 ML의 기술적 과제와 그에 대한 해결 노력에 대해 자세히 설명합니다.

2.1 자바 스크립트 환경
다른 환경. JS의 과제 중 하나는 다른 환경에서 실행된다는 것입니다. 계산은 서버 측 브라우저에서 클라이언트 측에서 일어날 수 있습니다. 가장 중요한 것은 Node.js 프레임 워크의 일부이며, 최근에는 Electron과 같은 프레임 워크를 통해 데스크톱에서 수행 될 수 있습니다. TensorFlow.js는이 모든 설정에서 작동하도록 설계되었습니다. 현재까지 대부분의 작업이 웹 브라우저에서 클라이언트 측 개발을 위해 조정되었습니다.

공연. 브라우저 환경과 관련된 두 번째 핵심 과제는 성능입니다. JS는 해석 된 언어이므로 일반적으로 C ++이나 Java와 같은 컴파일 된 언어의 속도와 수치 계산을위한 속도가 일치하지 않습니다.
C ++ 라이브러리에 바인딩 할 수있는 Python과 달리 브라우저는이 기능을 제공하지 않습니다. 보안상의 이유로 브라우저 애플리케이션은 GPU에 직접 액세스하지 못합니다. GPU는 일반적으로 최신 심층 학습 시스템에서 수치 계산이 이루어지는 곳입니다.
이러한 성능 문제를 해결하기 위해 몇 가지 새로운 JS 표준이 등장하고 있습니다. 한 가지 주목할만한 해결책은 브라우저에서 직접 해석되고 실행될 수있는 C ++ 프로그램을 바이트 코드로 컴파일하는 방법 인 WebAssembly (Haas et al., 2017)입니다. 특정 작업의 경우 WebAssembly는 일반 JS를 능가 할 수 있습니다. 최신 브라우저는 OpenGL을 JS에 노출시키는 API 인 WebGL (Kronos, 2011)도 지원합니다. OpenGL은 2D 및 3D 벡터 그래픽을 렌더링하기위한 교차 언어, 교차 플랫폼 API로서 게임 및 기타 고성능 렌더링 작업을 웹 페이지에서 직접 수행 할 수있게합니다. 서버 측에서는 JS 라이브러리가 Node.js의 N-API 인터페이스 (Nodejs.org, 2017)를 통해 C 및 C ++로 작성된 기존 기본 모듈에 바인딩 할 수 있습니다.

브라우저 간 호환성. JS는 모든 플랫폼에서 실행되는 응용 프로그램을 쉽게 작성할 수 있도록 표준화 된 웹 API를 사용하여 모든 주요 브라우저에서 지원되는 교차 플랫폼 언어로 설계되었습니다. 실제로 브라우저는 약간 다른 구현과 우선 순위를 가진 여러 벤더에 의해 만들어졌습니다. 예를 들어 크롬과 파이어 폭스가 WebGL 2.0 (WebGL 1.0보다 크게 향상된 기능)을 지원하는 반면, 애플의 사파리는 WebGL 1.0과
WebGPU (Jackson, 2017)와 같은 미래의 기술로 초점을 옮겼습니다. 웹 응용 프로그램 작성자는 자신의 응용 프로그램에서 이러한 불일치를 숨기기 위해 열심히 노력해야하며 대다수의 플랫폼에서 테스트하기 위해 광범위한 테스트 인프라가 필요합니다.

단일 스레드 실행. JS 환경의 다른 문제 중 하나는 단일 스레드 환경입니다. JS에는 웹 페이지 레이아웃, JS 코드, 이벤트 처리 등이 이루어지는 '기본 스레드'( 'UI 스레드'라고도 함)가 있습니다. 이렇게하면 개발 모델의 일부 측면이 크게 단순화되지만 응용 프로그램 개발자는 페이지의 다른 부분이 느려질 수 있으므로 주 스레드를 차단하지 않도록주의해야합니다. 따라서 잘 설계된 JS 라이브러리는 동기식 API의 단순성과 비동기식 API의 비 차단 이점을 조심스럽게 균형을 유지해야합니다.

2.2 브라우저 기반 환경에서의 기회
공유 가능성. TensorFlow.js의 주요 동기는 추가 설치없이 표준 브라우저에서 ML을 실행할 수 있다는 것입니다. TensorFlow.js로 작성된 모델과 응용 프로그램을 웹에서 쉽게 공유 할 수 있으므로 기계 학습을위한 진입 장벽이 낮아집니다. 이것은 교육용 사례와 현장 기여자의 다양성을 높이기 위해 특히 중요합니다.
상호 작용. 기계 학습 관점에서 볼 때, 웹 브라우저의 대화 형 특성과 웹 API의 다양한 기능은 교육 및 연구 목적을 모두 지원할 수있는 다양한 신규 사용자 중심 ML 응용 프로그램의 가능성을 열어줍니다. (Olah, 2014) 및 (Smilkov et al., 2016)과 같은 신경 네트워크의 시각화는 기계 학습의 기본 개념을 가르치는 데 널리 사용되었습니다.
온 - 디바이스 계산. 마지막으로 브라우저의 웹 카메라, 마이크 및 가속도계와 같은 장치 하드웨어의 다양한 구성 요소에 대한 표준화 된 액세스를 통해 ML 모델과 센서 데이터를 쉽게 통합 할 수 있습니다. 이러한 통합의 중요한 결과는 사용자 데이터가 온 - 장치 상태를 유지하고 사용자 개인 정보를 보호 할 수있어 의료, 액세스 가능성 및 개인화 된 ML 도메인에서 응용 프로그램을 사용할 수 있다는 것입니다.
예를 들어, 말하기 장애가있는 사용자는 전화기를 사용하여 오디오 샘플을 수집하여 브라우저에서 개인화 된 모델을 학습 할 수 있습니다. Federated Learning (McMahan et al., 2016)이라는 또 다른 기술을 사용하면 장치가 중요한 데이터를 장치에 보관하면서 중앙 모델을 공동으로 교육 할 수 있습니다. 브라우저는 이러한 유형의 응용 프로그램을위한 자연스러운 플랫폼입니다.


2.3 관련 연구
JS 생태계의 인기와 고유 한 이점을 감안할 때, 많은 오픈 소스 브라우저 기반 ML 라이브러리가 존재한다는 것은 놀랄 일이 아닙니다. 초보자가 신경을 구축하고 훈련시킬 수있는 ConvNetJS (Karpathy, 2014), Synaptic (Cazala, 2014), Brain.js (Plummer, 2010), Mind (Miller, 2015) 및 Neataptic (Wagenaar, 2017) 몇 줄의 코드만으로 네트워크를 구성 할 수 있습니다. 보다 전문화 된 JS ML 라이브러리에는 강화 학습에 중점을 두는 NeuroJS (Huenermann, 2016) 및 REINFORCEjs (Karpathy, 2015)와 같은 NLP 응용 프로그램에 초점을 맞춘 Compromise (Kelly, 2014) 및 Natural (Umbel, 2011)이 포함됩니다. ML.js (Zasso, 2014)는 파이썬 기반의 scikit-learn과 비슷한 ML 유틸리티의보다 일반적인 세트를 제공합니다 (Pedregosa et al.
2011).
이러한 라이브러리는 브라우저의 하드웨어 가속에 대한 액세스를 제공하지 않습니다. 브라우저의 연산 가속은 대화 형 사용 사례 및 최첨단 ML 모델의 대기 시간을 최소화하고 계산 효율성을 위해 중요합니다. 몇몇 라이브러리는 TensorFire (Kwok 등, 2017), Propel (TensorFlow.js 위에 구축 됨) (Dahl, 2017) 및 Keras.js와 같은 하드웨어 가속화를 활용하려고 시도했습니다
(첸, 2016 년), 그러나 더 이상 활발히 유지되지 않는다. WebDNN (Hidaka et al., 2017)은 JS의 또 다른 심층 학습 라이브러리로서 TensorFlow, Keras, PyTorch, Chainer 및 Caffe에서 개발 된 사전 모델을 실행할 수 있습니다. 계산을 가속화하기 위해 WebDNN은 처음에 Apple에서 제안한 기술인 WebGPU (Jackson, 2017)를 사용합니다. WebGPU는 초기 탐색 단계에 있으며 현재 Safari 브라우저의 시험 버전 인 Safari Technology Preview에서만 지원됩니다. 다른 브라우저의 대안으로 WebDNN은 WebAssembly (Haas et al., 2017)를 사용합니다.이 도구는 컴파일 된 C 및 C ++ 코드를 브라우저에서 직접 실행할 수 있습니다.
WebAssembly는 모든 주요 브라우저에서 지원되지만, WebGL 및 WebGPU와 같은 성능을내는 데 필요한 중요한 구성 요소 인 SIMD 지침이 없습니다.


3 디자인 및 API
TensorFlow.js의 목표는 다른 유명한 ML 라이브러리와 몇 가지 중요한 점에서 다릅니다. 특히, TensorFlow.js는 ML을 JS 생태계에 도입하여 ML 경험이 제한적이거나없는 다양한 JS 개발자에게 권한을 부여하도록 설계되었습니다 (Anonymous, 2018). 동시에 숙련 된 ML 사용자와 교습 애호가가 자신의 작업을 JS로 쉽게 마이그레이션 할 수있게하여 다양한 기능과 API를 필요로했습니다. 이 두 가지 목표는 종종 충돌로 이어지며 사용 편의성과 기능성간에 균형을 잘 맞춰야합니다. 마지막으로, 증가하는 사용자 기반을 가진 새로운 라이브러리로서 누락 된 기능이 성능보다 우선시되었습니다. 이러한 목표는 성능이 대개 1 위 목표 인 인기있는 심층 학습 라이브러리 (Abadi et al., 2016; Paszke et al., 2017)와 다른 JS ML 라이브러리 (2.3 절 참조)와 다른 점이다. 기능성을 완벽하게 단순화합니다. 예를 들어 TensorFlow.js의 주요 차별화 요소는 단순히 Python으로 작성된 모델의 실행 환경이 아닌 JS에서 직접 모델을 작성하고 교육하는 기능입니다.

3.1 개요
TensorFlow.js의 API는 TensorFlow 이후에 주로 모델링됩니다. JS 환경에만 적용되는 몇 가지 예외가 있습니다. TensorFlow와 마찬가지로 핵심 데이터 구조는 Tensor입니다. TensorFlow.js API는 JS 배열에서 텐서를 생성하는 메서드 및 텐서로 작동하는 수학 함수를 제공합니다. TensorFlow.js는 그림 1과 같이 브라우저 및 서버 측에서 실행되도록 설계되었습니다. 브라우저 내부에서 실행될 때 WebGL을 통해 장치의 GPU를 사용하여 빠른 병렬화 된 부동 소수점 계산을 가능하게합니다. Node.js에서 TensorFlow.js는 TensorFlow C 라이브러리에 바인딩되어 TensorFlow에 대한 모든 액세스를 가능하게합니다. TensorFlow.js는 일반 JS로 구현 된 폴백 (단순화를 위해 그림에서 생략)으로 느린 CPU 구현을 제공합니다. 이 폴백은 모든 실행 환경에서 실행할 수 있으며 환경에 WebGL 또는 TensorFlow 바이너리에 대한 액세스 권한이 없을 때 자동으로 사용됩니다


그림 1은 아키텍처의 고수준 개략도를 보여줍니다. TensorFlow.js는 하위 수준의 선형 대수 연산 (예 : 행렬 곱셈, 텐서 추가 등)을 제공하는 Ops API와 상위 수준 모델 구축 블록 및 모범 사례를 제공하는 레이어 API의 두 세트로 구성됩니다. 신경 네트워크에 중점을 둡니다. Layers API는 널리 채택 된 Keras API (Chollet et al., 2015)를 기반으로하는 TensorFlow Python의 tf.keras 네임 스페이스를 모델로합니다.
Listing 1. 계층 API로 단일 레이어 선형 모델을 작성하고 합성 데이터로 교육하고 보이지 않는 데이터 포인트에 대해 예측하는 방법을 보여주는 TensorFlow.js 프로그램의 예제.

3.2 레이어 API
초보자 및 모델의 운영 레벨 세부 정보에 관심이없는 사람들은 낮은 수준의 작업 API가 복잡하고 오류가 발생하기 쉽습니다. 반면에 광범위하게 채택 된 Keras 라이브러리 (Chollet et al., 2015)는 깊은 학습에 중점을 둔 높은 수준의 빌딩 블록을 제공합니다. 신중하게 고안된 API를 통해 Keras는 심층 학습 초보자와 응용 ML 입문가들 사이에서 인기가 있습니다. API의 핵심은 모델과 레이어의 개념입니다. 사용자는 미리 정의 된 레이어 세트를 모아서 모델을 만들 수 있습니다. 각 레이어에는인지 부하를 줄이기위한 적절한 기본 매개 변수가 있습니다. 이러한 이유로 TensorFlow.js는 직렬화 형식을 포함하여 Keras API를 가능한 한 가깝게 반영하는 Layers API를 제공합니다.
이를 통해 Keras와 TensorFlow.js 사이에 양방향 문이 가능합니다. 사용자는 TensorFlow.js에서 사전 교육 된 Keras 모델을로드하고 (5.1 절 참조) 수정하고 직렬화 한 다음 Keras Python으로 다시로드 할 수 있습니다. Listing 1은 Layers API를 사용하여 모델을 교육하는 예제이다.

3.3 조작과 커널
TensorFlow와 마찬가지로 연산은 실행되는 물리적 장치와 독립적 인 추상 계산 (예 : 행렬 곱셈)을 나타냅니다. 연산은 4 장에서 다룰 수학 함수의 장치 별 구현 인 커널을 호출합니다.

3.4 백엔드
장치 별 커널 구현을 지원하기 위해 TensorFlow.js에는 백엔드 개념이 있습니다. 백엔드는 텐서를 뒷받침하는 TypedArray를 저장하는 데 사용되는 read () 및 write ()와 같은 메소드뿐만 아니라 커널을 구현합니다. Tensors는 데이터를 백업하는 데이터와 분리되므로 변형 및 복제와 같은 작업을 효과적으로 수행 할 수 없습니다. 이것은 같은 데이터 컨테이너 (TypedArray)를 가리키는 텐서의 얕은 복사본을 만들어서 얻을 수 있습니다. 텐서가 처리 될 때 기본 데이터 컨테이너에 대한 참조 횟수를 줄이고 참조가 남아 있지 않으면 데이터 컨테이너 자체를 폐기합니다.


3.5 자동 차별화
광범위한 기능이 주요 설계 목표 중 하나 였기 때문에 TensorFlow.js는 자동 차별화를 지원하고 모델을 교육하고 그라데이션을 계산하는 API를 제공합니다. 가장 일반적인 두 가지 자동 차별화 스타일은 그래프 기반과 열망입니다. 그래프 기반 엔진은 계산 그래프를 작성하고 나중에 실행하기위한 API를 제공합니다. 그라디언트를 계산할 때 엔진은 그래프를 정적으로 분석하여 그라데이션 계산 그래프를 추가로 만듭니다.
이 접근법은 성능면에서 더 우수하며 직렬화가 쉽습니다. 한편, 열망하는 차별화 엔진은 다른 접근법을 취한다 (Paszke et al., 2017; Abadi et al., 2016; Maclaurin et al., 2015). eager 모드에서는 작업이 호출 될 때 즉시 계산이 수행되므로 인쇄하거나 디버거를 사용하여 결과를 더 쉽게 검사 할 수 있습니다. 또 다른 이점은 모델이 실행되는 동안 호스트 언어의 모든 기능을 사용할 수 있다는 것입니다. 사용자는 사용하기 어렵고 복잡한 스택 추적을 생성하는 특수 제어 흐름 API 대신 기본 if 및 while 루프를 사용할 수 있습니다.
이러한 장점으로 인해 TensorFlow Eager (Shankar & Dobson, 2017) 및 PyTorch (Paszke 외., 2017)와 같은 열정적 스타일의 차별화 엔진이 빠르게 인기를 얻고 있습니다. TensorFlow.js는 디자인 목표 중 중요한 부분이 성능보다 사용의 편의성을 우선시하는 것이기 때문에 열정적 인 차별화 스타일을 지원합니다.


3.6 비동기 실행
JS는 페이지 레이아웃 및 이벤트 처리와 같은 작업과 공유되는 단일 스레드에서 실행됩니다. 즉, 장기 실행 JS 함수로 인해 페이지 처리 속도가 느려지거나 이벤트 처리 지연이 발생할 수 있습니다. 이 문제를 완화하기 위해 JS 사용자는 최신 JS 언어의 필수 구성 요소 인 이벤트 콜백 및 약속에 의존합니다. 저명한 예로는 비동기 I / O와 이벤트 중심 프로그래밍에 의존하는 Node.js가 있습니다.
고성능 동시 프로그램 개발 그러나 콜백과 비동기 함수는 복잡한 코드로 이어질 수 있습니다. TensorFlow.js는 직관적 인 API를 제공하려는 설계 목표를 달성하기 위해 동기식 기능의 단순성과 비동기식 기능의 이점을 조화시키는 것을 목표로합니다. 예를 들어, tf.matMul ()과 같은 연산은 의도적으로 동기식이며 데이터가 아직 계산되지 않을 수있는 텐서를 반환합니다. 이를 통해 사용자는 디버그하기 쉬운 정기적 인 동기식 코드를 작성할 수 있습니다. 사용자가 텐서를지지하는 데이터를 검색해야하는 경우 비동기 tensor.data () 함수를 제공합니다.이 함수는 작업이 완료되면 해결되는 약속을 반환합니다. 따라서 비동기 코드의 사용은 단일 data () 호출로 현지화 될 수 있습니다.
사용자는 차단 호출 인 tensor.dataSync ()를 호출 할 수도 있습니다. 그림 2와 3은 각각 tensor.dataSync () 및 tensor.data ()를 호출 할 때 브라우저의 타임 라인을 보여줍니다.

그림 3. 브라우저에서 data ()에 대한 비동기 호출 타임 라인. 주 스레드는 GPU가 작업을 실행하는 동안 해제되고 텐서가 준비되고 다운로드 될 때 data () 약속이 해결됩니다.


3.7 메모리 관리
JS는 자동 가비지 수집을 제공합니다. 그러나 브라우저에서 WebGL 메모리는 자동으로 가비지 수집되지 않습니다. 이 때문에 최종 결정이 이루어지지 않아 모든 백엔드에 대한 API를 명시 적으로 메모리를 관리합니다. 텐서에 의해 할당 된 메모리를 처리하기 위해 사용자는 tensor.dispose ()를 호출 할 수 있습니다. 이 접근법은 비교적 간단하지만 사용자는 모든 텐서 객체에 대한 참조를 가져야 만 처리 할 수 ​​있습니다. 종종 모델은 체인으로 작성됩니다.
작업의 블록, 그래서 처분을 위해 체인을 깨는 것은 번거로울 수 있습니다. 텐서는 불변이고 연산은 기능적이기 때문에 하나의 연산 호출은 상당한 수의 중간 텐서를 할당 할 수 있습니다. 이러한 중간 텐서를 처리하는 것을 잊어 버리면 메모리 누수가 발생하고 응용 프로그램이 크게 느려집니다.
TensorFlow.js는 다른 접근 방식을 제공합니다. 함수는 JS의 1 차 시민이며 기본 JS API의 상당 부분이 함수를 인수로 사용하기 때문에 사용자는 tf.tidy (()를 호출하여 동기 함수 f를 래핑 할 수있는 범위 지정 메커니즘을 제공하기로 결정했습니다. f ()). 이것은 f를 즉시 호출하고, f의 반환 결과를 제외하고 한 번 f 내부에서 생성 된 모든 중간 텐서를 처리합니다. 우리는이 메커니즘을 우리 도서관에서 광범위하게 사용합니다. 내부적으로 메모리를 관리하는 model.fit (), model.predict () 및 model.evaluate ()와 같은 모델 수준 API로 인해 Layers API 사용자는 명시 적 메모리 관리가 필요하지 않습니다.

3.8 디버깅 및 프로파일 링
TensorFlow.js는 개발자가 URL 변경이나 기능 플래그를 통해 액세스 할 수있는 성능 및 수치 안정성과 관련된 일반적인 문제를 이해할 수 있도록 도와주는 다양한 디버깅 도구 세트를 제공합니다. 사용자는 호출 된 모든 커널을 프로파일 링하여 출력 형태, 메모리 공간 및 장치 별 타이밍 정보를 볼 수 있습니다. 이 모드에서는 모든 텐서가 GPU에서 다운로드되고 NaN이 있는지 확인됩니다. 첫 번째 라인에서 예외가 발생하면 NaN이 도입되어 모델 개발자에게 연산이 수치 적 불안정성의 원인임을 보여줍니다. TensorFlow.js는 TensorFlow.js 작업을 호출하는 함수 타이밍을 지정하기 위해 tf.time (f)도 제공합니다. tf.time (f)를 호출하면 함수 f가 실행되고 시간이 지정됩니다. 각 백엔드는 타이밍이 장치 일 수 있으므로 타이밍 기능을 담당합니다.
특유한. 예를 들어, WebGL 백엔드는 데이터를 업로드하고 다운로드하는 시간을 제외하고 정확한 GPU 시간을 측정합니다. 보다 일반적인 API 인 tf.profile (f)도 마찬가지로 함수 f를 취해 함수의 효과를 나타내는 객체를 메모리에 반환합니다. 객체는 새로 할당 된 텐서 수와 함수를 실행하여 생성 된 바이트 수와 함수 내에 할당 된 최대 텐서와 메모리를 포함합니다. 피크 메모리 사용량을 이해하는 것은 휴대 전화와 같이 제한된 메모리를 사용하는 장치에서 실행할 때 특히 중요합니다.

3.9 성과
성능이 가장 중요한 단일 목표는 아니지만 JS에서 실제 ML을 구현하는 데 중요했습니다. 브라우저에서 TensorFlow.js는 WebGL API를 사용하여 GPU를 사용하여 계산을 병렬 처리합니다. 수치 계산을 위해 WebGL을 사용함으로써 우리는 2 배의 속도 향상을 달성 할 수있었습니다. 이는 근본적으로 활성화 된 것입니다
브라우저에서 실제 ML 모델을 실행합니다. 서버 측에서 TensorFlow.js는 TensorFlow C API에 직접 바인딩합니다.이 API는 기본 하드웨어 가속을 최대한 활용합니다. 표 1은 일반 JS CPU에 비해 ​​이러한 구현의 속도 향상을 보여줍니다. MobileNet v1 1.0 (Howard et al., 2017)의 단일 추론을 측정하여 크기 224x224x3의 입력 이미지를 평균 100 회 실행합니다.
GTX 1080을 언급 한 것 이외의 모든 측정은 MacBook Pro 2014 노트북에서 측정되는 반면 GTX 1080 측정은 데스크탑 컴퓨터에서 측정됩니다. 유능한 GTX 1080 그래픽 카드를 사용하는 사람들은 WebGL 및 Node.js CPU 백엔드가 일반 JS 백엔드보다 2 배 더 빠르다는 점에 유의하십시오.
TensorFlow.js가 출시 된 이후로 우리는 WebGL 활용도를 향상시키는 데 상당한 진전을 이루었습니다. 주목할만한 개선점은 패킹입니다. 여기서 우리는 (1 채널 만 사용하는 대신) 텍셀의 4 개 채널 모두에 부동 소수점 값을 저장합니다. 패킹은 양방향 모바일에서 PoseNet (Oved, 2018)과 같은 모델의 1.3-1.4x 속도 향상을 가져 왔습니다.
및 데스크톱 장치. 우리는 WebGL 구현을 계속 연구 할 것이지만 WebGL과 CUDA 사이의 성능 차이는 3-10 배입니다. 우리는 WebGL의 작업 그룹 및 공유 메모리 액세스 부족, CUDA (Nickolls 외, 2008) 및 OpenGL Compute 쉐이더 (Shreiner et al., 2013)와 같은 범용 컴퓨팅 (GPGPU) 프레임 워크에서 제공되는 이점으로 인한 차이가 있다고 생각합니다. ). 아래 섹션 4.3에서 논의하는 바와 같이 향후 WebGPU (Jackson, 2017) 표준은 성능 격차를 줄이기위한 유망한 수단이라고 믿습니다.

4 구현
이 절에서는 TensorFlow.js에서 지원하는 다양한 백엔드의 특정 제약 조건과 구현에 대해 설명합니다.


4.1 브라우저 및 WebGL
깊은 학습과 과학 컴퓨팅의 출현과 현대 GPU 아키텍처의 발전으로 GPGPU의 사용은 엄청나게 증가했습니다. 현대의 JS 가상 머신은 일반 JS를 광범위하게 최적화 할 수 있지만 그 성능은 GPU가 제공하는 계산 능력보다 훨씬 낮습니다 (표 1 참조). GPU를 활용하기 위해 TensorFlow.js는 저수준 3D 그래픽 API를 제공하는 크로스 플랫폼 웹 표준 인 WebGL을 사용합니다. OpenCL 및 CUDA와 달리 WebGL API는 GPGPU를 명시 적으로 지원하지 않는 OpenGL ES 사양 (Shreiner 외, 2013)을 기반으로합니다.
3 개의 TensorFlow.js 백엔드 중에서 WebGL 백엔드가 가장 복잡합니다. 이러한 복잡성은 일반 JS로 작성된 CPU 백엔드보다 2 배 더 빠르다는 사실에 의해 정당화됩니다. 수치 계산을 위해 WebGL을 다시 사용할 수 있다는 사실은 브라우저에서 실제 ML 모델을 실행하는 것을 근본적으로 가능하게 한 것입니다. WebGL의 한계와 복잡성을 해결하기 위해 우리는 계산을 나타내는 WebGL 조각 셰이더를 실행하는 GPGPUContext라는 추상 레이어를 작성했습니다. 그래픽 프로그램에서 조각 쉐이더는 일반적으로 화면에 렌더링 할 픽셀의 색상을 생성하는 데 사용됩니다. 조각 셰이더는 각 픽셀에 대해 독립적으로 또는 병렬로 실행됩니다. TensorFlow.js는 ML 계산을 가속화하기 위해이 병렬화를 이용합니다.
WebGL 백엔드에서 드로잉 파이프 라인은 장면 지오메트리가 단위 사각형을 나타내도록 설정됩니다. 프래그먼트 셰이더 프로그램을 실행할 때 출력 텐서를 뒷받침하는 텍스처를 프레임 버퍼에 바인딩하고 프래그먼트 셰이더 프로그램을 실행합니다. 즉, 조각 쉐이더 main () 함수는 4와 같이 각 출력 값에 대해 병렬로 실행됩니다. 간단히하기 위해 텐서를 뒤집는 텍스처의 빨강 채널 만 사용합니다 (그림에서 'R'로 표시) . WebGL 2.0 장치에서는 gl.R32F 텍스처 유형을 사용하므로 녹색, 파란색 및 알파 채널 ( 'G', 'B'및 'A'로 각각 표시)에 대한 메모리 할당을 피할 수 있습니다. 앞으로의 작업에서 TensorFlow.js는 WebGL 1.0 장치의 모든 채널을 활용할 것이므로 GPU의 샘플러 캐시를 더 잘 활용할 수 있습니다.



